{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "theoretical-failure",
   "metadata": {},
   "source": [
    "# JIT Engine: Sparse Vector x Sparse Vector\n",
    "\n",
    "This example will go over how to compile MLIR code for multiplying sparse vectors in an element-wise fashion. \n",
    "\n",
    "Accomplishing this task is mostly applying the knowledge from our previous tutorials on sparse tensors and dense tensors. Thus, this will be more of a demonstration or example than it will be a tutorial. \n",
    "\n",
    "Letâ€™s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subsequent-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir_graphblas\n",
    "import mlir_graphblas.sparse_utils\n",
    "import numpy as np\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-toner",
   "metadata": {},
   "source": [
    "This is the code we'll use to multiply two sparse vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "christian-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_mul_s = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i) -> (i)>,\n",
    "    affine_map<(i) -> (i)>,\n",
    "    affine_map<(i) -> (i)>\n",
    "  ],\n",
    "  sparse = [\n",
    "    [ \"S\" ],\n",
    "    [ \"S\" ],\n",
    "    [ \"D\" ]\n",
    "  ],\n",
    "  iterator_types = [\"parallel\"],\n",
    "  doc = \"Sparse Vector Multiply\"\n",
    "}\n",
    "\n",
    "#CV64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"compressed\" ],\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @sparse_vector_multiply(%arga: tensor<8xf32, #CV64>, %argb: tensor<8xf32, #CV64>) -> tensor<8xf32> {\n",
    "  %output_storage = arith.constant dense<0.0> : tensor<8xf32>\n",
    "  %0 = linalg.generic #trait_mul_s\n",
    "    ins(%arga, %argb: tensor<8xf32, #CV64>, tensor<8xf32, #CV64>)\n",
    "    outs(%output_storage: tensor<8xf32>) {\n",
    "      ^bb(%a: f32, %b: f32, %x: f32):\n",
    "        %0 = arith.mulf %a, %b : f32\n",
    "        linalg.yield %0 : f32\n",
    "  } -> tensor<8xf32>\n",
    "  return %0 : tensor<8xf32>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-threat",
   "metadata": {},
   "source": [
    "These are the passes we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boring-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-constant-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-std\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-openmp-to-llvm\",\n",
    "    \"--convert-arith-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "    \"--reconcile-unrealized-casts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-speed",
   "metadata": {},
   "source": [
    "Let's generate our Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sharp-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.add(mlir_text, passes)\n",
    "sparse_vector_multiply = engine.sparse_vector_multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-browse",
   "metadata": {},
   "source": [
    "Let's generate our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extended-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to np.array([0.0, 1.1, 2.2, 3.3, 0, 0, 0, 7.7], dtype=np.float32)\n",
    "\n",
    "indices = np.array([\n",
    "    [0], \n",
    "    [1], \n",
    "    [2], \n",
    "    [3], \n",
    "    [7], \n",
    "], dtype=np.uint64) # Coordinates\n",
    "values = np.array([0.0, 1.1, 2.2, 3.3, 7.7], dtype=np.float32)\n",
    "sizes = np.array([8], dtype=np.uint64)\n",
    "sparsity = np.array([True], dtype=np.bool8)\n",
    "\n",
    "a = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cutting-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to np.array([0, 0, 0, 3.3, 4.4, 0, 0, 7.7], dtype=np.float32)\n",
    "\n",
    "indices = np.array([\n",
    "    [3], \n",
    "    [4],\n",
    "    [7],\n",
    "], dtype=np.uint64) # Coordinates\n",
    "values = np.array([3.3, 4.4, 7.7], dtype=np.float32)\n",
    "sizes = np.array([8], dtype=np.uint64)\n",
    "sparsity = np.array([True], dtype=np.bool8)\n",
    "\n",
    "b = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-touch",
   "metadata": {},
   "source": [
    "Let's grab our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nonprofit-bridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.      ,  0.      ,  0.      , 10.889999,  0.      ,  0.      ,\n",
       "        0.      , 59.289997], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = sparse_vector_multiply(a, b)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-marathon",
   "metadata": {},
   "source": [
    "Let's see if our results match what we would expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "secret-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dense = np.array([0.0, 1.1, 2.2, 3.3, 0, 0, 0, 7.7], dtype=np.float32)\n",
    "b_dense = np.array([0, 0, 0, 3.3, 4.4, 0, 0, 7.7], dtype=np.float32)\n",
    "np_result = a_dense * b_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "written-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.      ,  0.      ,  0.      , 10.889999,  0.      ,  0.      ,\n",
       "        0.      , 59.289997], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "early-breach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(answer == np_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
