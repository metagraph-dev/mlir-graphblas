{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial-penalty",
   "metadata": {},
   "source": [
    "# JIT Engine: Scalar x Tensor\n",
    "\n",
    "This example will go over how to compile MLIR code for multiplying a scalar by a tensor. \n",
    "\n",
    "Previous tutorials have gone over how to broadcast vectors. For the simple task of multiplying a each tensor's elements by a scalar, broadcasting may be unwarranted or unnecessary. We'll go over how to implement this in a much simpler and more straightforward fashion. \n",
    "\n",
    "Letâ€™s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forbidden-consideration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using development graphblas-opt: /Users/pnguyen/code/mlir-graphblas/mlir_graphblas/src/build/bin/graphblas-opt\n"
     ]
    }
   ],
   "source": [
    "import mlir_graphblas\n",
    "import numpy as np\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-router",
   "metadata": {},
   "source": [
    "Here's the MLIR code we'll use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pending-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_add = {\n",
    " indexing_maps = [\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>\n",
    " ],\n",
    " iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "func @scale(%arg_tensor: tensor<2x3xf32>, %arg_scalar: f32) -> tensor<2x3xf32> {\n",
    "  %output_storage = arith.constant dense<0.0> : tensor<2x3xf32>\n",
    "  %answer = linalg.generic #trait_add\n",
    "    ins(%arg_tensor: tensor<2x3xf32>)\n",
    "    outs(%arg_tensor: tensor<2x3xf32>) {\n",
    "      ^bb(%a: f32, %s: f32):\n",
    "        %scaled = arith.mulf %a, %arg_scalar : f32\n",
    "        linalg.yield %scaled : f32\n",
    "    } -> tensor<2x3xf32>\n",
    " return %answer : tensor<2x3xf32>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-terrorism",
   "metadata": {},
   "source": [
    "These are the passes we'll utilize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "detected-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--graphblas-structuralize\",\n",
    "    \"--graphblas-optimize\",\n",
    "    \"--graphblas-lower\",\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-cf\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-openmp-to-llvm\",\n",
    "    \"--convert-arith-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "    \"--reconcile-unrealized-casts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-resolution",
   "metadata": {},
   "source": [
    "Let's compile our MLIR code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "packed-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scale']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-whale",
   "metadata": {},
   "source": [
    "Let's try out our compiled function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "diverse-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab our callable\n",
    "scale = engine.scale\n",
    "\n",
    "# generate inputs\n",
    "a = np.arange(6, dtype=np.float32).reshape([2,3])\n",
    "\n",
    "# generate output\n",
    "result = scale(a, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "introductory-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 100., 200.],\n",
       "       [300., 400., 500.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-aurora",
   "metadata": {},
   "source": [
    "Let's verify that our function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accepting-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(result == a*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
