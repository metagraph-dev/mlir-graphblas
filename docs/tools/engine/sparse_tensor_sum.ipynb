{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-challenge",
   "metadata": {},
   "source": [
    "# JIT Engine: Sparse Tensor Summation\n",
    "\n",
    "This example will go over how to compile MLIR code for taking the sum over a sparse tensor.\n",
    "\n",
    "Previous tutorials covered how to handle functions on sparse tensors and how to take the sum of dense tensors. Accomplishing this task is mostly applying the knowledge from these tutorials. Thus, this will be more of a demonstration or example than it will be a tutorial. \n",
    "\n",
    "Letâ€™s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acting-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir_graphblas\n",
    "import mlir_graphblas.sparse_utils\n",
    "import numpy as np\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-arcade",
   "metadata": {},
   "source": [
    "This is the code we'll use to take the sum over a sparse tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressive-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_sum_reduction = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i,j,k) -> (i,j,k)>,\n",
    "    affine_map<(i,j,k) -> ()>\n",
    "  ],\n",
    "  sparse = [\n",
    "    [ \"S\", \"S\", \"S\" ],\n",
    "    [ ]\n",
    "  ],\n",
    "  iterator_types = [\"reduction\", \"reduction\", \"reduction\"],\n",
    "  doc = \"Sparse Tensor Sum\"\n",
    "}\n",
    "\n",
    "#SparseEncoding = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j,k) -> (i,j,k)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @sparse_sum(%argA: tensor<10x20x30xf32, #SparseEncoding>) -> f32 {\n",
    "  %output_storage = constant dense<0.0> : tensor<f32>\n",
    "  %reduction = linalg.generic #trait_sum_reduction\n",
    "    ins(%argA: tensor<10x20x30xf32, #SparseEncoding>)\n",
    "    outs(%output_storage: tensor<f32>) {\n",
    "      ^bb(%a: f32, %x: f32):\n",
    "        %0 = addf %x, %a : f32\n",
    "        linalg.yield %0 : f32\n",
    "  } -> tensor<f32>\n",
    "  %answer = tensor.extract %reduction[] : tensor<f32>\n",
    "  return %answer : f32\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-armenia",
   "metadata": {},
   "source": [
    "These are the passes we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "commercial-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--tensor-constant-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-std\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-smile",
   "metadata": {},
   "source": [
    "Let's generate our Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cubic-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.add(mlir_text, passes)\n",
    "sparse_sum = engine.sparse_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-verification",
   "metadata": {},
   "source": [
    "Let's generate our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bored-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array([\n",
    "    [0, 0, 0], \n",
    "    [1, 1, 3], \n",
    "    [2, 1, 6], \n",
    "    [3, 9, 9], \n",
    "    [4, 9, 12], \n",
    "    [9, 9, 15], \n",
    "    [9, 9, 18], \n",
    "    [9, 15, 21], \n",
    "    [9, 15, 24], \n",
    "    [9, 19, 27],\n",
    "], dtype=np.uint64)\n",
    "values = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], dtype=np.float32)\n",
    "sizes = np.array([10, 20, 30], dtype=np.uint64)\n",
    "sparsity = np.array([True, True, True], dtype=np.bool8)\n",
    "\n",
    "sparse_tensor = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-nudist",
   "metadata": {},
   "source": [
    "Let's grab our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "developed-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = sparse_sum(sparse_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-atlas",
   "metadata": {},
   "source": [
    "Let's see if our results match what we would expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "micro-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer == np.sum(values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
