{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ready-gender",
   "metadata": {},
   "source": [
    "# JIT Engine: Tensor + Tensor\n",
    "\n",
    "This example will go over how to compile MLIR code to a function callable from Python.\n",
    "\n",
    "The example MLIR code we’ll use here performs element-wise tensor addition.\n",
    "\n",
    "Let’s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using development graphblas-opt: /Users/pnguyen/code/mlir-graphblas/mlir_graphblas/src/build/bin/graphblas-opt\n"
     ]
    }
   ],
   "source": [
    "import mlir_graphblas\n",
    "import numpy as np\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-registrar",
   "metadata": {},
   "source": [
    "We'll use the same set of passes to optimize and compile all of our examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--graphblas-structuralize\",\n",
    "    \"--graphblas-optimize\",\n",
    "    \"--graphblas-lower\",\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-cf\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-openmp-to-llvm\",\n",
    "    \"--convert-arith-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "    \"--reconcile-unrealized-casts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-spare",
   "metadata": {},
   "source": [
    "## Fixed-Size Tensor Addition\n",
    "\n",
    "Here’s some MLIR code to add two 32-bit floating point tensors of with the shape 2x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forced-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_add = {\n",
    " indexing_maps = [\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>\n",
    " ],\n",
    " iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "func @matrix_add_f32(%arga: tensor<2x3xf32>, %argb: tensor<2x3xf32>) -> tensor<2x3xf32> {\n",
    "  %answer = linalg.generic #trait_add\n",
    "    ins(%arga, %argb: tensor<2x3xf32>, tensor<2x3xf32>)\n",
    "    outs(%arga: tensor<2x3xf32>) {\n",
    "      ^bb(%a: f32, %b: f32, %s: f32):\n",
    "        %sum = arith.addf %a, %b : f32\n",
    "        linalg.yield %sum : f32\n",
    "  } -> tensor<2x3xf32>\n",
    "  return %answer : tensor<2x3xf32>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-forestry",
   "metadata": {},
   "source": [
    "Let's compile our MLIR code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funded-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix_add_f32']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-amount",
   "metadata": {},
   "source": [
    "Let's try out our compiled function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sonic-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab our callable\n",
    "matrix_add_f32 = engine.matrix_add_f32\n",
    "\n",
    "# generate inputs\n",
    "a = np.arange(6, dtype=np.float32).reshape([2, 3])\n",
    "b = np.full([2, 3], 100, dtype=np.float32)\n",
    "\n",
    "# generate output\n",
    "result = matrix_add_f32(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "invisible-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100., 101., 102.],\n",
       "       [103., 104., 105.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-priest",
   "metadata": {},
   "source": [
    "Let's verify that our function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hidden-toddler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(result == np.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-particle",
   "metadata": {},
   "source": [
    "## Arbitrary-Size Tensor Addition\n",
    "\n",
    "The above example created a function to add two matrices of size 2x3. This function won't work if we want to add two matrices of size 4x5 or any other size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "random-judges",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array([[ 0.,  1.,  2.,  3.,  4.],\n       [ 5.,  6.,  7.,  8.,  9.],\n       [10., 11., 12., 13., 14.],\n       [15., 16., 17., 18., 19.]], dtype=float32) is expected to have size 2 in the 0th dimension but has size 4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m20\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull([\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m], \u001b[38;5;241m100\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmatrix_add_f32\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py:843\u001b[0m, in \u001b[0;36mMlirJitEngine._generate_zero_or_single_valued_functions.<locals>.python_callable\u001b[0;34m(mlir_function, encoders, c_callable, decoder, *args)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mlir_function\u001b[38;5;241m.\u001b[39margs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m args but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m     )\n\u001b[1;32m    842\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m (encoder(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg, encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, encoders))\n\u001b[0;32m--> 843\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mencoded_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m encoded_result \u001b[38;5;241m=\u001b[39m c_callable(\u001b[38;5;241m*\u001b[39mencoded_args)\n\u001b[1;32m    845\u001b[0m result \u001b[38;5;241m=\u001b[39m decoder(encoded_result)\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py:842\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mlir_function\u001b[38;5;241m.\u001b[39margs):\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mlir_function\u001b[38;5;241m.\u001b[39margs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m args but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m     )\n\u001b[0;32m--> 842\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m (\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg, encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, encoders))\n\u001b[1;32m    843\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(encoded_args, [])\n\u001b[1;32m    844\u001b[0m encoded_result \u001b[38;5;241m=\u001b[39m c_callable(\u001b[38;5;241m*\u001b[39mencoded_args)\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py:400\u001b[0m, in \u001b[0;36minput_tensor_to_ctypes.<locals>.encoder\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dimensions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is expected to have rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dimensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but has rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(arg\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m \u001b[43mvalidate_arg_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m [arg, arg, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    403\u001b[0m encoded_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py:310\u001b[0m, in \u001b[0;36minput_tensor_to_ctypes.<locals>.validate_arg_shape\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    305\u001b[0m     expected_dim_size \u001b[38;5;241m=\u001b[39m dimensions[dim_index]\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    307\u001b[0m         expected_dim_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mshape[dim_index] \u001b[38;5;241m!=\u001b[39m expected_dim_size\n\u001b[1;32m    309\u001b[0m     ):\n\u001b[0;32m--> 310\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    311\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is expected to have size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_dim_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth dimension but has size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mshape[dim_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m         )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: array([[ 0.,  1.,  2.,  3.,  4.],\n       [ 5.,  6.,  7.,  8.,  9.],\n       [10., 11., 12., 13., 14.],\n       [15., 16., 17., 18., 19.]], dtype=float32) is expected to have size 2 in the 0th dimension but has size 4."
     ]
    }
   ],
   "source": [
    "a = np.arange(20, dtype=np.float32).reshape([4, 5])\n",
    "b = np.full([4, 5], 100, dtype=np.float32)\n",
    "matrix_add_f32(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-thumb",
   "metadata": {},
   "source": [
    "While it's nice that the JIT engine is able to detect that there's a size mismatch, it'd be nicer to have a function that can add two tensors of arbitrary size. \n",
    "\n",
    "We'll now show how to create such a function for matrix of 32-bit integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reserved-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_add = {\n",
    " indexing_maps = [\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>\n",
    " ],\n",
    " iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "func @matrix_add_i32(%arga: tensor<?x?xi32>, %argb: tensor<?x?xi32>) -> tensor<?x?xi32> {\n",
    "  // Find the max dimensions of both args\n",
    "  %c0 = arith.constant 0 : index\n",
    "  %c1 = arith.constant 1 : index\n",
    "  %arga_dim0 = tensor.dim %arga, %c0 : tensor<?x?xi32>\n",
    "  %arga_dim1 = tensor.dim %arga, %c1 : tensor<?x?xi32>\n",
    "  %argb_dim0 = tensor.dim %argb, %c0 : tensor<?x?xi32>\n",
    "  %argb_dim1 = tensor.dim %argb, %c1 : tensor<?x?xi32>\n",
    "  %dim0_gt = arith.cmpi \"ugt\", %arga_dim0, %argb_dim0 : index\n",
    "  %dim1_gt = arith.cmpi \"ugt\", %arga_dim1, %argb_dim1 : index\n",
    "  %output_dim0 = arith.select %dim0_gt, %arga_dim0, %argb_dim0 : index\n",
    "  %output_dim1 = arith.select %dim1_gt, %arga_dim1, %argb_dim1 : index\n",
    "  %output_tensor = linalg.init_tensor [%output_dim0, %output_dim1] : tensor<?x?xi32>\n",
    "  \n",
    "  // Perform addition\n",
    "  %answer = linalg.generic #trait_add\n",
    "    ins(%arga, %argb: tensor<?x?xi32>, tensor<?x?xi32>)\n",
    "    outs(%output_tensor: tensor<?x?xi32>) {\n",
    "      ^bb(%a: i32, %b: i32, %s: i32):\n",
    "        %sum = arith.addi %a, %b : i32\n",
    "        linalg.yield %sum : i32\n",
    "    } -> tensor<?x?xi32>\n",
    " return %answer : tensor<?x?xi32>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-confidentiality",
   "metadata": {},
   "source": [
    "The compilation of this MLIR code will be the same as our first example. The main difference is in how we wrote our MLIR code (notice the use of \"?x?\" when denoting the shapes of tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pediatric-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "engine.add(mlir_text, passes)\n",
    "matrix_add_i32 = engine.matrix_add_i32\n",
    "\n",
    "# generate inputs\n",
    "a = np.arange(20, dtype=np.int32).reshape([4, 5])\n",
    "b = np.full([4, 5], 100, dtype=np.int32)\n",
    "\n",
    "# generate output\n",
    "result = matrix_add_i32(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chronic-pressure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 101, 102, 103, 104],\n",
       "       [105, 106, 107, 108, 109],\n",
       "       [110, 111, 112, 113, 114],\n",
       "       [115, 116, 117, 118, 119]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instructional-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(result == np.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-translator",
   "metadata": {},
   "source": [
    "Note that we get some level of safety regarding the tensor types as we get an exception if we pass in tensors with the wrong dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "protective-hearing",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array([[100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100]]) is expected to have dtype <class 'numpy.int32'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmatrix_add_i32\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py:843\u001b[0m, in \u001b[0;36mMlirJitEngine._generate_zero_or_single_valued_functions.<locals>.python_callable\u001b[0;34m(mlir_function, encoders, c_callable, decoder, *args)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mlir_function\u001b[38;5;241m.\u001b[39margs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m args but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m     )\n\u001b[1;32m    842\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m (encoder(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg, encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, encoders))\n\u001b[0;32m--> 843\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mencoded_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m encoded_result \u001b[38;5;241m=\u001b[39m c_callable(\u001b[38;5;241m*\u001b[39mencoded_args)\n\u001b[1;32m    845\u001b[0m result \u001b[38;5;241m=\u001b[39m decoder(encoded_result)\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py:842\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mlir_function\u001b[38;5;241m.\u001b[39margs):\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mlir_function\u001b[38;5;241m.\u001b[39margs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m args but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m     )\n\u001b[0;32m--> 842\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m (\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg, encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, encoders))\n\u001b[1;32m    843\u001b[0m encoded_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(encoded_args, [])\n\u001b[1;32m    844\u001b[0m encoded_result \u001b[38;5;241m=\u001b[39m c_callable(\u001b[38;5;241m*\u001b[39mencoded_args)\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py:392\u001b[0m, in \u001b[0;36minput_tensor_to_ctypes.<locals>.encoder\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is expected to be an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mndarray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m     )\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m element_np_type:\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is expected to have dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melement_np_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    394\u001b[0m     )\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dimensions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is expected to have rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dimensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but has rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(arg\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: array([[100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100]]) is expected to have dtype <class 'numpy.int32'>"
     ]
    }
   ],
   "source": [
    "matrix_add_i32(a, b.astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-neighbor",
   "metadata": {},
   "source": [
    "Note that in the MLIR code, each of our output tensor's dimensions is the max of each dimension of our inputs. \n",
    "\n",
    "A consequence of this is that our function doesn't enforce that our inputs are the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "living-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate differently shaped inputs\n",
    "a = np.arange(6, dtype=np.int32).reshape([2, 3])\n",
    "b = np.full([4, 5], 100, dtype=np.int32)\n",
    "\n",
    "# generate output\n",
    "result = matrix_add_i32(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6cd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "economic-supply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "private-union",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       100,        101,        102, -536870912,          7],\n",
       "       [       103,        104,        105,          0,         48],\n",
       "       [1852990827,  808348773,  862337379,  758342450, 1667588407],\n",
       "       [ 879047725,  809053497, 1680696121, 1650798691,  878994488]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-scroll",
   "metadata": {},
   "source": [
    "This result is somewhat unexpected. The weird numbers we see (the zeros and large numbers) are come from the garbage/uninitialized values in the memory for our output (i.e. `%output_memref`). \n",
    "\n",
    "This is an implementation problem with how we wrote our MLIR code as there's no enforcement of the need for both inputs to be the same shape. Special care must be taken when dealing with arbitrary sized tensors or else we might get bugs or unexpected results as shown here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
