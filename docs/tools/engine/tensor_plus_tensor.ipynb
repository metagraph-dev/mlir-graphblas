{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ready-gender",
   "metadata": {},
   "source": [
    "# JIT Engine: Tensor + Tensor\n",
    "\n",
    "This example will go over how to compile MLIR code to a function callable from Python.\n",
    "\n",
    "The example MLIR code we’ll use here performs element-wise tensor addition.\n",
    "\n",
    "Let’s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir_graphblas\n",
    "import numpy as np\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-registrar",
   "metadata": {},
   "source": [
    "We'll use the same set of passes to optimize and compile all of our examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--tensor-constant-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-std\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-spare",
   "metadata": {},
   "source": [
    "## Fixed-Size Tensor Addition\n",
    "\n",
    "Here’s some MLIR code to add two 32-bit floating point tensors of with the shape 2x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forced-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_add = {\n",
    " indexing_maps = [\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>\n",
    " ],\n",
    " iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "func @matrix_add_f32(%arga: tensor<2x3xf32>, %argb: tensor<2x3xf32>) -> tensor<2x3xf32> {\n",
    "  %answer = linalg.generic #trait_add\n",
    "    ins(%arga, %argb: tensor<2x3xf32>, tensor<2x3xf32>)\n",
    "    outs(%arga: tensor<2x3xf32>) {\n",
    "      ^bb(%a: f32, %b: f32, %s: f32):\n",
    "        %sum = addf %a, %b : f32\n",
    "        linalg.yield %sum : f32\n",
    "  } -> tensor<2x3xf32>\n",
    "  return %answer : tensor<2x3xf32>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-forestry",
   "metadata": {},
   "source": [
    "Let's compile our MLIR code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funded-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix_add_f32']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-amount",
   "metadata": {},
   "source": [
    "Let's try out our compiled function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sonic-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab our callable\n",
    "matrix_add_f32 = engine.matrix_add_f32\n",
    "\n",
    "# generate inputs\n",
    "a = np.arange(6, dtype=np.float32).reshape([2, 3])\n",
    "b = np.full([2, 3], 100, dtype=np.float32)\n",
    "\n",
    "# generate output\n",
    "result = matrix_add_f32(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "invisible-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100., 101., 102.],\n",
       "       [103., 104., 105.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-priest",
   "metadata": {},
   "source": [
    "Let's verify that our function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hidden-toddler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(result == np.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-particle",
   "metadata": {},
   "source": [
    "## Arbitrary-Size Tensor Addition\n",
    "\n",
    "The above example created a function to add two matrices of size 2x3. This function won't work if we want to add two matrices of size 4x5 or any other size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "random-judges",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array([[ 0.,  1.,  2.,  3.,  4.],\n       [ 5.,  6.,  7.,  8.,  9.],\n       [10., 11., 12., 13., 14.],\n       [15., 16., 17., 18., 19.]], dtype=float32) is expected to have size 2 in the 0th dimension but has size 4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yj/nmf5xtns3hx6qgdnybj964q80000gp/T/ipykernel_87449/2503430335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmatrix_add_f32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py\u001b[0m in \u001b[0;36mpython_callable\u001b[0;34m(mlir_function, encoders, c_callable, decoder, *args)\u001b[0m\n\u001b[1;32m    780\u001b[0m                     )\n\u001b[1;32m    781\u001b[0m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m                 \u001b[0mencoded_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    779\u001b[0m                         \u001b[0;34mf\"{name} expected {len(mlir_function.args)} args but got {len(args)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                     )\n\u001b[0;32m--> 781\u001b[0;31m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                 \u001b[0mencoded_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    337\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_dim_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 ):\n\u001b[0;32m--> 339\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    340\u001b[0m                         \u001b[0;34mf\"{repr(arg)} is expected to have size {expected_dim_size} in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                         \u001b[0;34mf\"{dim_index}th dimension but has size {arg.shape[dim_index]}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array([[ 0.,  1.,  2.,  3.,  4.],\n       [ 5.,  6.,  7.,  8.,  9.],\n       [10., 11., 12., 13., 14.],\n       [15., 16., 17., 18., 19.]], dtype=float32) is expected to have size 2 in the 0th dimension but has size 4."
     ]
    }
   ],
   "source": [
    "a = np.arange(20, dtype=np.float32).reshape([4, 5])\n",
    "b = np.full([4, 5], 100, dtype=np.float32)\n",
    "matrix_add_f32(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-thumb",
   "metadata": {},
   "source": [
    "While it's nice that the JIT engine is able to detect that there's a size mismatch, it'd be nicer to have a function that can add two tensors of arbitrary size. \n",
    "\n",
    "We'll now show how to create such a function for matrix of 32-bit integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reserved-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_add = {\n",
    " indexing_maps = [\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>,\n",
    "   affine_map<(i, j) -> (i, j)>\n",
    " ],\n",
    " iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "func @matrix_add_i32(%arga: tensor<?x?xi32>, %argb: tensor<?x?xi32>) -> tensor<?x?xi32> {\n",
    "  // Find the max dimensions of both args\n",
    "  %c0 = constant 0 : index\n",
    "  %c1 = constant 1 : index\n",
    "  %arga_dim0 = tensor.dim %arga, %c0 : tensor<?x?xi32>\n",
    "  %arga_dim1 = tensor.dim %arga, %c1 : tensor<?x?xi32>\n",
    "  %argb_dim0 = tensor.dim %argb, %c0 : tensor<?x?xi32>\n",
    "  %argb_dim1 = tensor.dim %argb, %c1 : tensor<?x?xi32>\n",
    "  %dim0_gt = cmpi \"ugt\", %arga_dim0, %argb_dim0 : index\n",
    "  %dim1_gt = cmpi \"ugt\", %arga_dim1, %argb_dim1 : index\n",
    "  %output_dim0 = select %dim0_gt, %arga_dim0, %argb_dim0 : index\n",
    "  %output_dim1 = select %dim1_gt, %arga_dim1, %argb_dim1 : index\n",
    "  %output_memref = memref.alloca(%output_dim0, %output_dim1) : memref<?x?xi32>\n",
    "  %output_tensor = memref.tensor_load %output_memref : memref<?x?xi32>\n",
    "  \n",
    "  // Perform addition\n",
    "  %answer = linalg.generic #trait_add\n",
    "    ins(%arga, %argb: tensor<?x?xi32>, tensor<?x?xi32>)\n",
    "    outs(%output_tensor: tensor<?x?xi32>) {\n",
    "      ^bb(%a: i32, %b: i32, %s: i32):\n",
    "        %sum = addi %a, %b : i32\n",
    "        linalg.yield %sum : i32\n",
    "    } -> tensor<?x?xi32>\n",
    " return %answer : tensor<?x?xi32>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-confidentiality",
   "metadata": {},
   "source": [
    "The compilation of this MLIR code will be the same as our first example. The main difference is in how we wrote our MLIR code (notice the use of \"?X?\" when denoting the shapes of tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pediatric-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "engine.add(mlir_text, passes)\n",
    "matrix_add_i32 = engine.matrix_add_i32\n",
    "\n",
    "# generate inputs\n",
    "a = np.arange(20, dtype=np.int32).reshape([4, 5])\n",
    "b = np.full([4, 5], 100, dtype=np.int32)\n",
    "\n",
    "# generate output\n",
    "result = matrix_add_i32(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chronic-pressure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 101, 102, 103, 104],\n",
       "       [105, 106, 107, 108, 109],\n",
       "       [110, 111, 112, 113, 114],\n",
       "       [115, 116, 117, 118, 119]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instructional-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(result == np.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-translator",
   "metadata": {},
   "source": [
    "Note that we get some level of safety regarding the tensor types as we get an exception if we pass in tensors with the wrong dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "protective-hearing",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array([[100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100]]) is expected to have dtype <class 'numpy.int32'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yj/nmf5xtns3hx6qgdnybj964q80000gp/T/ipykernel_87449/510596375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix_add_i32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py\u001b[0m in \u001b[0;36mpython_callable\u001b[0;34m(mlir_function, encoders, c_callable, decoder, *args)\u001b[0m\n\u001b[1;32m    780\u001b[0m                     )\n\u001b[1;32m    781\u001b[0m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m                 \u001b[0mencoded_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    779\u001b[0m                         \u001b[0;34mf\"{name} expected {len(mlir_function.args)} args but got {len(args)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                     )\n\u001b[0;32m--> 781\u001b[0;31m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m                 \u001b[0mencoded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                 \u001b[0mencoded_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mencoded_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/engine.py\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 )\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{repr(arg)} is expected to have dtype {np_type}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 raise ValueError(\n",
      "\u001b[0;31mTypeError\u001b[0m: array([[100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100]]) is expected to have dtype <class 'numpy.int32'>"
     ]
    }
   ],
   "source": [
    "matrix_add_i32(a, b.astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-neighbor",
   "metadata": {},
   "source": [
    "Note that in the MLIR code, each of our output tensor's dimensions is the max of each dimension of our inputs. \n",
    "\n",
    "A consequence of this is that our function doesn't enforce that our inputs are the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "living-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate differently shaped inputs\n",
    "a = np.arange(6, dtype=np.int32).reshape([2, 3])\n",
    "b = np.full([4, 5], 100, dtype=np.int32)\n",
    "\n",
    "# generate output\n",
    "result = matrix_add_i32(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "economic-supply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "private-union",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       100,        101,        102, 1073743867,          6],\n",
       "       [       103,        104,        105,          0,        101],\n",
       "       [1852990827, 1714318437,  962869552,  761619769,  842032697],\n",
       "       [1667511341,  926428470,  808280369, 1714829668,  946157106]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-scroll",
   "metadata": {},
   "source": [
    "This result is somewhat unexpected. The weird numbers we see (the zeros and large numbers) are come from the arbitrarily initialized values in the memory for our output (i.e. `%output_memref`). \n",
    "\n",
    "This is an implementation problem with how we wrote our MLIR code as there's no enforcement of the need for both inputs to be the same shape. Special care must be taken when dealing with arbitrary sized tensors or else we might get bugs or unexpected results as shown here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
