{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "working-finance",
   "metadata": {},
   "source": [
    "# JIT Engine: Matrix + Broadcasted Vector\n",
    "\n",
    "This example will go over how to compile MLIR code intended to add a matrix to a vector using broadcasting.\n",
    "\n",
    "In other words, we want to write a function equivalent to this NumPy code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "knowing-prerequisite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100., 100., 100.],\n",
       "       [101., 101., 101.],\n",
       "       [102., 102., 102.],\n",
       "       [103., 103., 103.]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.full([4,3], 100, dtype=np.float32)\n",
    "vector = np.arange(4, dtype=np.float32)\n",
    "\n",
    "matrix + np.expand_dims(vector, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-rebound",
   "metadata": {},
   "source": [
    "Letâ€™s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir_graphblas\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-leader",
   "metadata": {},
   "source": [
    "Here's the MLIR code we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrative-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_matplusvec = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i,j) -> (i,j)>,\n",
    "    affine_map<(i,j) -> (i)>,\n",
    "    affine_map<(i,j) -> (i,j)>\n",
    "  ],\n",
    "  iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "func @mat_plus_vec(%arga: tensor<10x?xf32>, %argb: tensor<10xf32>) -> tensor<10x?xf32> {\n",
    "  %c1 = arith.constant 1 : index\n",
    "  %arga_dim1 = tensor.dim %arga, %c1 : tensor<10x?xf32>\n",
    "  %output_memref = memref.alloca(%arga_dim1) : memref<10x?xf32>\n",
    "  %output_tensor = memref.tensor_load %output_memref : memref<10x?xf32>\n",
    "  %answer = linalg.generic #trait_matplusvec\n",
    "      ins(%arga, %argb : tensor<10x?xf32>, tensor<10xf32>)\n",
    "      outs(%output_tensor: tensor<10x?xf32>) {\n",
    "        ^bb(%a: f32, %b: f32, %x: f32):\n",
    "          %sum = arith.addf %a, %b : f32\n",
    "          linalg.yield %sum : f32\n",
    "  } -> tensor<10x?xf32>\n",
    "  return %answer : tensor<10x?xf32>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-dance",
   "metadata": {},
   "source": [
    "Note that the input matrix has an arbitrary number of columns. \n",
    "\n",
    "These are the passes we'll use to optimize and compile our MLIR code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fossil-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--graphblas-structuralize\",\n",
    "    \"--graphblas-optimize\",\n",
    "    \"--graphblas-lower\",\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-constant-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-std\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-openmp-to-llvm\",\n",
    "    \"--convert-arith-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "    \"--reconcile-unrealized-casts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-interval",
   "metadata": {},
   "source": [
    "Let's compile our MLIR code using our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "architectural-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.add(mlir_text, passes)\n",
    "mat_plus_vec = engine.mat_plus_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-inclusion",
   "metadata": {},
   "source": [
    "Let's see how well our function works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "offshore-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate inputs\n",
    "m = np.arange(40, dtype=np.float32).reshape([10,4])\n",
    "v = np.arange(10, dtype=np.float32) / 10\n",
    "\n",
    "# generate output\n",
    "result = mat_plus_vec(m, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interim-confidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  2. ,  3. ],\n",
       "       [ 4.1,  5.1,  6.1,  7.1],\n",
       "       [ 8.2,  9.2, 10.2, 11.2],\n",
       "       [12.3, 13.3, 14.3, 15.3],\n",
       "       [16.4, 17.4, 18.4, 19.4],\n",
       "       [20.5, 21.5, 22.5, 23.5],\n",
       "       [24.6, 25.6, 26.6, 27.6],\n",
       "       [28.7, 29.7, 30.7, 31.7],\n",
       "       [32.8, 33.8, 34.8, 35.8],\n",
       "       [36.9, 37.9, 38.9, 39.9]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-knowing",
   "metadata": {},
   "source": [
    "Let's verify that our result is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uniform-tackle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(result == m + np.expand_dims(v, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
