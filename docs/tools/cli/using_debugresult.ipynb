{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "patient-tamil",
   "metadata": {},
   "source": [
    "# Using DebugResult\n",
    "\n",
    "Here, we will show how to use `DebugResult` to debug some problems we might encounter when using our mlir-opt CLI Wrapper.\n",
    "\n",
    "Letâ€™s first import some necessary classes and generate an instance of our mlir-opt CLI Wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparative-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using development graphblas-opt: /Users/pnguyen/code/mlir-graphblas/mlir_graphblas/src/build/bin/graphblas-opt\n"
     ]
    }
   ],
   "source": [
    "from mlir_graphblas import MlirOptCli\n",
    "\n",
    "cli = MlirOptCli(executable=None, options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-conviction",
   "metadata": {},
   "source": [
    "## Generate Example Input\n",
    "\n",
    "Let's say we have a bunch of MLIR code that we're not familiar with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intensive-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_string = \"\"\"\n",
    "#trait_sum_reduction = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i,j,k) -> (i,j,k)>,  // A\n",
    "    affine_map<(i,j,k) -> ()>        // x (scalar out)\n",
    "  ],\n",
    "  iterator_types = [\"reduction\", \"reduction\", \"reduction\"],\n",
    "  doc = \"x += SUM_ijk A(i,j,k)\"\n",
    "}\n",
    "\n",
    "#sparseTensor = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j,k) -> (i,j,k)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @func_f32(%argA: tensor<10x20x30xf32, #sparseTensor>) -> f32 {\n",
    "  %out_tensor = linalg.init_tensor [] : tensor<f32>\n",
    "  %reduction = linalg.generic #trait_sum_reduction\n",
    "     ins(%argA: tensor<10x20x30xf32, #sparseTensor>)\n",
    "    outs(%out_tensor: tensor<f32>) {\n",
    "      ^bb(%a: f32, %x: f32):\n",
    "        %0 = arith.addf %x, %a : f32\n",
    "        linalg.yield %0 : f32\n",
    "  } -> tensor<f32>\n",
    "  %answer = tensor.extract %reduction[] : tensor<f32>\n",
    "  return %answer : f32\n",
    "}\n",
    "\"\"\"\n",
    "mlir_bytes = mlir_string.encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-accounting",
   "metadata": {},
   "source": [
    "Since we're not familiar with this code, we don't exactly know what passes are necessary or in what order they should go in.\n",
    "\n",
    "Let's say that this is the first set of passes we try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggregate-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--arith-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-vector-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-math-to-libm\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-openmp-to-llvm\",\n",
    "    \"--convert-arith-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "    \"--reconcile-unrealized-casts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-excitement",
   "metadata": {},
   "source": [
    "Let's see what results we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifty-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stderr] <stdin>:20:16: error: failed to legalize operation 'builtin.unrealized_conversion_cast' that was explicitly marked illegal\n",
      "[stderr]   %reduction = linalg.generic #trait_sum_reduction\n",
      "[stderr]                ^\n",
      "[stderr] <stdin>:20:16: note: see current operation: %4 = \"builtin.unrealized_conversion_cast\"(%3) : (i64) -> index\n"
     ]
    },
    {
     "ename": "MlirOptError",
     "evalue": "<stdin>:20:16: error: failed to legalize operation 'builtin.unrealized_conversion_cast' that was explicitly marked illegal\n  %reduction = linalg.generic #trait_sum_reduction\n               ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlirOptError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcli\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_passes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlir_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/mlir-graphblas/mlir_graphblas/cli.py:93\u001b[0m, in \u001b[0;36mMlirOptCli.apply_passes\u001b[0;34m(self, file, passes)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_input(fp)\n\u001b[1;32m     92\u001b[0m err\u001b[38;5;241m.\u001b[39mdebug_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_passes(\u001b[38;5;28minput\u001b[39m, passes) \u001b[38;5;28;01mif\u001b[39;00m passes \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mMlirOptError\u001b[0m: <stdin>:20:16: error: failed to legalize operation 'builtin.unrealized_conversion_cast' that was explicitly marked illegal\n  %reduction = linalg.generic #trait_sum_reduction\n               ^"
     ]
    }
   ],
   "source": [
    "result = cli.apply_passes(mlir_bytes, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-japanese",
   "metadata": {},
   "source": [
    "We get an exception. \n",
    "\n",
    "Unfortunately, the exception message isn't very clear as it only gives us the immediate error message but doesn't inform us of the context in which it occurred, e.g. in which pass the error occurred (if any) or if any necessary passes are missing. \n",
    "\n",
    "We only know that the operation `builtin.unrealized_conversion_cast` shows up somewhere and that it's a problem.\n",
    "\n",
    "Let's try to use the `debug_passes` method instead of the `apply_passes` to get more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broke-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cli.debug_passes(mlir_bytes, passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affecting-addiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================\n",
       "  Error when running reconcile-unrealized-casts  \n",
       "=================================================\n",
       "<stdin>:24:10: error: failed to legalize operation 'builtin.unrealized_conversion_cast' that was explicitly marked illegal\n",
       "    %4 = builtin.unrealized_conversion_cast %3 : i64 to index\n",
       "         ^\n",
       "<stdin>:24:10: note: see current operation: %4 = \"builtin.unrealized_conversion_cast\"(%3) : (i64) -> index loc(\"<stdin>\":24:10)\n",
       "\n",
       "\n",
       "=======================================\n",
       "  Input to reconcile-unrealized-casts  \n",
       "=======================================\n",
       "             10        20        30        40        50        60        70        80        90        100       110       120       130       140       150       160       170       180       190       200       \n",
       "    12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123\n",
       "    -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
       "  1|module attributes {llvm.data_layout = \"\"} {\n",
       "  2|  llvm.func @malloc(i64) -> !llvm.ptr<i8>\n",
       "  3|  llvm.func @sparseValuesF32(%arg0: !llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
       "  4|    %0 = llvm.mlir.constant(1 : index) : i64\n",
       "  5|    %1 = llvm.alloca %0 x !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "  6|    llvm.call @_mlir_ciface_sparseValuesF32(%1, %arg0) : (!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) -> ()\n",
       "  7|    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "  8|    llvm.return %2 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "  9|  }\n",
       " 10|  llvm.func @_mlir_ciface_sparseValuesF32(!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
       " 11|  llvm.func @sparsePointers64(%arg0: !llvm.ptr<i8>, %arg1: i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
       " 12|    %0 = llvm.mlir.constant(1 : index) : i64\n",
       " 13|    %1 = llvm.alloca %0 x !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       " 14|    llvm.call @_mlir_ciface_sparsePointers64(%1, %arg0, %arg1) : (!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) -> ()\n",
       " 15|    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       " 16|    llvm.return %2 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 17|  }\n",
       " 18|  llvm.func @_mlir_ciface_sparsePointers64(!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
       " 19|  llvm.func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       " 20|    %0 = llvm.mlir.constant(0 : index) : i64\n",
       " 21|    %1 = builtin.unrealized_conversion_cast %0 : i64 to index\n",
       " 22|    %2 = builtin.unrealized_conversion_cast %1 : index to i64\n",
       " 23|    %3 = llvm.mlir.constant(1 : index) : i64\n",
       " 24|    %4 = builtin.unrealized_conversion_cast %3 : i64 to index\n",
       " 25|    %5 = builtin.unrealized_conversion_cast %4 : index to i64\n",
       " 26|    %6 = llvm.mlir.constant(2 : index) : i64\n",
       " 27|    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32\n",
       " 28|    %8 = llvm.call @sparsePointers64(%arg0, %0) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 29|    %9 = builtin.unrealized_conversion_cast %8 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       " 30|    %10 = builtin.unrealized_conversion_cast %9 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 31|    %11 = llvm.call @sparsePointers64(%arg0, %3) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 32|    %12 = builtin.unrealized_conversion_cast %11 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       " 33|    %13 = builtin.unrealized_conversion_cast %12 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 34|    %14 = llvm.call @sparsePointers64(%arg0, %6) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 35|    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       " 36|    %16 = builtin.unrealized_conversion_cast %15 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 37|    %17 = llvm.call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 38|    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>\n",
       " 39|    %19 = builtin.unrealized_conversion_cast %18 : memref<?xf32> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 40|    %20 = llvm.mlir.constant(1 : index) : i64\n",
       " 41|    %21 = llvm.mlir.null : !llvm.ptr<f32>\n",
       " 42|    %22 = llvm.getelementptr %21[%20] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       " 43|    %23 = llvm.ptrtoint %22 : !llvm.ptr<f32> to i64\n",
       " 44|    %24 = llvm.call @malloc(%23) : (i64) -> !llvm.ptr<i8>\n",
       " 45|    %25 = llvm.bitcast %24 : !llvm.ptr<i8> to !llvm.ptr<f32>\n",
       " 46|    %26 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       " 47|    %27 = llvm.insertvalue %25, %26[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       " 48|    %28 = llvm.insertvalue %25, %27[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       " 49|    %29 = llvm.mlir.constant(0 : index) : i64\n",
       " 50|    %30 = llvm.insertvalue %29, %28[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       " 51|    %31 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       " 52|    llvm.store %7, %31 : !llvm.ptr<f32>\n",
       " 53|    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       " 54|    %33 = llvm.load %32 : !llvm.ptr<f32>\n",
       " 55|    %34 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 56|    %35 = llvm.getelementptr %34[%2] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       " 57|    %36 = llvm.load %35 : !llvm.ptr<i64>\n",
       " 58|    %37 = builtin.unrealized_conversion_cast %36 : i64 to index\n",
       " 59|    %38 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 60|    %39 = llvm.getelementptr %38[%5] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       " 61|    %40 = llvm.load %39 : !llvm.ptr<i64>\n",
       " 62|    %41 = builtin.unrealized_conversion_cast %40 : i64 to index\n",
       " 63|    %42 = scf.for %arg1 = %37 to %41 step %4 iter_args(%arg2 = %33) -> (f32) {\n",
       " 64|      %46 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
       " 65|      %47 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
       " 66|      %48 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 67|      %49 = llvm.getelementptr %48[%47] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       " 68|      %50 = llvm.load %49 : !llvm.ptr<i64>\n",
       " 69|      %51 = builtin.unrealized_conversion_cast %50 : i64 to index\n",
       " 70|      %52 = llvm.add %46, %3  : i64\n",
       " 71|      %53 = builtin.unrealized_conversion_cast %52 : i64 to index\n",
       " 72|      %54 = builtin.unrealized_conversion_cast %53 : index to i64\n",
       " 73|      %55 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 74|      %56 = llvm.getelementptr %55[%54] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       " 75|      %57 = llvm.load %56 : !llvm.ptr<i64>\n",
       " 76|      %58 = builtin.unrealized_conversion_cast %57 : i64 to index\n",
       " 77|      %59 = scf.for %arg3 = %51 to %58 step %4 iter_args(%arg4 = %arg2) -> (f32) {\n",
       " 78|        %60 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
       " 79|        %61 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
       " 80|        %62 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 81|        %63 = llvm.getelementptr %62[%61] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       " 82|        %64 = llvm.load %63 : !llvm.ptr<i64>\n",
       " 83|        %65 = builtin.unrealized_conversion_cast %64 : i64 to index\n",
       " 84|        %66 = llvm.add %60, %3  : i64\n",
       " 85|        %67 = builtin.unrealized_conversion_cast %66 : i64 to index\n",
       " 86|        %68 = builtin.unrealized_conversion_cast %67 : index to i64\n",
       " 87|        %69 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 88|        %70 = llvm.getelementptr %69[%68] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       " 89|        %71 = llvm.load %70 : !llvm.ptr<i64>\n",
       " 90|        %72 = builtin.unrealized_conversion_cast %71 : i64 to index\n",
       " 91|        %73 = scf.for %arg5 = %65 to %72 step %4 iter_args(%arg6 = %arg4) -> (f32) {\n",
       " 92|          %74 = builtin.unrealized_conversion_cast %arg5 : index to i64\n",
       " 93|          %75 = llvm.extractvalue %19[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       " 94|          %76 = llvm.getelementptr %75[%74] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       " 95|          %77 = llvm.load %76 : !llvm.ptr<f32>\n",
       " 96|          %78 = llvm.fadd %arg6, %77  : f32\n",
       " 97|          scf.yield %78 : f32\n",
       " 98|        }\n",
       " 99|        scf.yield %73 : f32\n",
       "100|      }\n",
       "101|      scf.yield %59 : f32\n",
       "102|    }\n",
       "103|    %43 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "104|    llvm.store %42, %43 : !llvm.ptr<f32>\n",
       "105|    %44 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "106|    %45 = llvm.load %44 : !llvm.ptr<f32>\n",
       "107|    llvm.return %45 : f32\n",
       "108|  }\n",
       "109|}\n",
       "110|\n",
       "\n",
       "================================\n",
       "  Input to convert-std-to-llvm  \n",
       "================================\n",
       "module {\n",
       "  llvm.func @malloc(i64) -> !llvm.ptr<i8>\n",
       "  llvm.func @sparseValuesF32(%arg0: !llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
       "    %0 = llvm.mlir.constant(1 : index) : i64\n",
       "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.call @_mlir_ciface_sparseValuesF32(%1, %arg0) : (!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) -> ()\n",
       "    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.return %2 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "  }\n",
       "  llvm.func @_mlir_ciface_sparseValuesF32(!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
       "  llvm.func @sparsePointers64(%arg0: !llvm.ptr<i8>, %arg1: i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
       "    %0 = llvm.mlir.constant(1 : index) : i64\n",
       "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.call @_mlir_ciface_sparsePointers64(%1, %arg0, %arg1) : (!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) -> ()\n",
       "    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.return %2 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "  }\n",
       "  llvm.func @_mlir_ciface_sparsePointers64(!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
       "  llvm.func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %0 = llvm.mlir.constant(0 : index) : i64\n",
       "    %1 = builtin.unrealized_conversion_cast %0 : i64 to index\n",
       "    %2 = builtin.unrealized_conversion_cast %1 : index to i64\n",
       "    %3 = llvm.mlir.constant(1 : index) : i64\n",
       "    %4 = builtin.unrealized_conversion_cast %3 : i64 to index\n",
       "    %5 = builtin.unrealized_conversion_cast %4 : index to i64\n",
       "    %6 = llvm.mlir.constant(2 : index) : i64\n",
       "    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32\n",
       "    %8 = llvm.call @sparsePointers64(%arg0, %0) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %9 = builtin.unrealized_conversion_cast %8 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       "    %10 = builtin.unrealized_conversion_cast %9 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %11 = llvm.call @sparsePointers64(%arg0, %3) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %12 = builtin.unrealized_conversion_cast %11 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       "    %13 = builtin.unrealized_conversion_cast %12 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %14 = llvm.call @sparsePointers64(%arg0, %6) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       "    %16 = builtin.unrealized_conversion_cast %15 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %17 = llvm.call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>\n",
       "    %19 = builtin.unrealized_conversion_cast %18 : memref<?xf32> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %20 = llvm.mlir.constant(1 : index) : i64\n",
       "    %21 = llvm.mlir.null : !llvm.ptr<f32>\n",
       "    %22 = llvm.getelementptr %21[%20] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       "    %23 = llvm.ptrtoint %22 : !llvm.ptr<f32> to i64\n",
       "    %24 = llvm.call @malloc(%23) : (i64) -> !llvm.ptr<i8>\n",
       "    %25 = llvm.bitcast %24 : !llvm.ptr<i8> to !llvm.ptr<f32>\n",
       "    %26 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %27 = llvm.insertvalue %25, %26[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %28 = llvm.insertvalue %25, %27[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %29 = llvm.mlir.constant(0 : index) : i64\n",
       "    %30 = llvm.insertvalue %29, %28[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %31 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    llvm.store %7, %31 : !llvm.ptr<f32>\n",
       "    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %33 = llvm.load %32 : !llvm.ptr<f32>\n",
       "    %34 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %35 = llvm.getelementptr %34[%2] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "    %36 = llvm.load %35 : !llvm.ptr<i64>\n",
       "    %37 = builtin.unrealized_conversion_cast %36 : i64 to index\n",
       "    %38 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %39 = llvm.getelementptr %38[%5] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "    %40 = llvm.load %39 : !llvm.ptr<i64>\n",
       "    %41 = builtin.unrealized_conversion_cast %40 : i64 to index\n",
       "    %42 = scf.for %arg1 = %37 to %41 step %4 iter_args(%arg2 = %33) -> (f32) {\n",
       "      %46 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
       "      %47 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
       "      %48 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "      %49 = llvm.getelementptr %48[%47] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "      %50 = llvm.load %49 : !llvm.ptr<i64>\n",
       "      %51 = builtin.unrealized_conversion_cast %50 : i64 to index\n",
       "      %52 = llvm.add %46, %3  : i64\n",
       "      %53 = builtin.unrealized_conversion_cast %52 : i64 to index\n",
       "      %54 = builtin.unrealized_conversion_cast %53 : index to i64\n",
       "      %55 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "      %56 = llvm.getelementptr %55[%54] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "      %57 = llvm.load %56 : !llvm.ptr<i64>\n",
       "      %58 = builtin.unrealized_conversion_cast %57 : i64 to index\n",
       "      %59 = scf.for %arg3 = %51 to %58 step %4 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %60 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
       "        %61 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
       "        %62 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "        %63 = llvm.getelementptr %62[%61] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "        %64 = llvm.load %63 : !llvm.ptr<i64>\n",
       "        %65 = builtin.unrealized_conversion_cast %64 : i64 to index\n",
       "        %66 = llvm.add %60, %3  : i64\n",
       "        %67 = builtin.unrealized_conversion_cast %66 : i64 to index\n",
       "        %68 = builtin.unrealized_conversion_cast %67 : index to i64\n",
       "        %69 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "        %70 = llvm.getelementptr %69[%68] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "        %71 = llvm.load %70 : !llvm.ptr<i64>\n",
       "        %72 = builtin.unrealized_conversion_cast %71 : i64 to index\n",
       "        %73 = scf.for %arg5 = %65 to %72 step %4 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %74 = builtin.unrealized_conversion_cast %arg5 : index to i64\n",
       "          %75 = llvm.extractvalue %19[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "          %76 = llvm.getelementptr %75[%74] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       "          %77 = llvm.load %76 : !llvm.ptr<f32>\n",
       "          %78 = llvm.fadd %arg6, %77  : f32\n",
       "          scf.yield %78 : f32\n",
       "        }\n",
       "        scf.yield %73 : f32\n",
       "      }\n",
       "      scf.yield %59 : f32\n",
       "    }\n",
       "    %43 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    llvm.store %42, %43 : !llvm.ptr<f32>\n",
       "    %44 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %45 = llvm.load %44 : !llvm.ptr<f32>\n",
       "    llvm.return %45 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "==================================\n",
       "  Input to convert-arith-to-llvm  \n",
       "==================================\n",
       "module {\n",
       "  llvm.func @malloc(i64) -> !llvm.ptr<i8>\n",
       "  llvm.func @sparseValuesF32(%arg0: !llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
       "    %0 = llvm.mlir.constant(1 : index) : i64\n",
       "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.call @_mlir_ciface_sparseValuesF32(%1, %arg0) : (!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) -> ()\n",
       "    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.return %2 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "  }\n",
       "  llvm.func @_mlir_ciface_sparseValuesF32(!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
       "  llvm.func @sparsePointers64(%arg0: !llvm.ptr<i8>, %arg1: i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
       "    %0 = llvm.mlir.constant(1 : index) : i64\n",
       "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.call @_mlir_ciface_sparsePointers64(%1, %arg0, %arg1) : (!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) -> ()\n",
       "    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
       "    llvm.return %2 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "  }\n",
       "  llvm.func @_mlir_ciface_sparsePointers64(!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
       "  llvm.func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %0 = llvm.mlir.constant(0 : index) : i64\n",
       "    %1 = builtin.unrealized_conversion_cast %0 : i64 to index\n",
       "    %2 = builtin.unrealized_conversion_cast %1 : index to i64\n",
       "    %3 = llvm.mlir.constant(1 : index) : i64\n",
       "    %4 = builtin.unrealized_conversion_cast %3 : i64 to index\n",
       "    %5 = builtin.unrealized_conversion_cast %4 : index to i64\n",
       "    %6 = llvm.mlir.constant(2 : index) : i64\n",
       "    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32\n",
       "    %8 = llvm.call @sparsePointers64(%arg0, %0) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %9 = builtin.unrealized_conversion_cast %8 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       "    %10 = builtin.unrealized_conversion_cast %9 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %11 = llvm.call @sparsePointers64(%arg0, %3) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %12 = builtin.unrealized_conversion_cast %11 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       "    %13 = builtin.unrealized_conversion_cast %12 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %14 = llvm.call @sparsePointers64(%arg0, %6) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
       "    %16 = builtin.unrealized_conversion_cast %15 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %17 = llvm.call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>\n",
       "    %19 = builtin.unrealized_conversion_cast %18 : memref<?xf32> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %20 = llvm.mlir.constant(1 : index) : i64\n",
       "    %21 = llvm.mlir.null : !llvm.ptr<f32>\n",
       "    %22 = llvm.getelementptr %21[%20] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       "    %23 = llvm.ptrtoint %22 : !llvm.ptr<f32> to i64\n",
       "    %24 = llvm.call @malloc(%23) : (i64) -> !llvm.ptr<i8>\n",
       "    %25 = llvm.bitcast %24 : !llvm.ptr<i8> to !llvm.ptr<f32>\n",
       "    %26 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %27 = llvm.insertvalue %25, %26[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %28 = llvm.insertvalue %25, %27[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %29 = llvm.mlir.constant(0 : index) : i64\n",
       "    %30 = llvm.insertvalue %29, %28[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %31 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    llvm.store %7, %31 : !llvm.ptr<f32>\n",
       "    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %33 = llvm.load %32 : !llvm.ptr<f32>\n",
       "    %34 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %35 = llvm.getelementptr %34[%2] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "    %36 = llvm.load %35 : !llvm.ptr<i64>\n",
       "    %37 = builtin.unrealized_conversion_cast %36 : i64 to index\n",
       "    %38 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %39 = llvm.getelementptr %38[%5] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "    %40 = llvm.load %39 : !llvm.ptr<i64>\n",
       "    %41 = builtin.unrealized_conversion_cast %40 : i64 to index\n",
       "    %42 = scf.for %arg1 = %37 to %41 step %4 iter_args(%arg2 = %33) -> (f32) {\n",
       "      %46 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
       "      %47 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
       "      %48 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "      %49 = llvm.getelementptr %48[%47] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "      %50 = llvm.load %49 : !llvm.ptr<i64>\n",
       "      %51 = builtin.unrealized_conversion_cast %50 : i64 to index\n",
       "      %52 = llvm.add %46, %3  : i64\n",
       "      %53 = builtin.unrealized_conversion_cast %52 : i64 to index\n",
       "      %54 = builtin.unrealized_conversion_cast %53 : index to i64\n",
       "      %55 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "      %56 = llvm.getelementptr %55[%54] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "      %57 = llvm.load %56 : !llvm.ptr<i64>\n",
       "      %58 = builtin.unrealized_conversion_cast %57 : i64 to index\n",
       "      %59 = scf.for %arg3 = %51 to %58 step %4 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %60 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
       "        %61 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
       "        %62 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "        %63 = llvm.getelementptr %62[%61] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "        %64 = llvm.load %63 : !llvm.ptr<i64>\n",
       "        %65 = builtin.unrealized_conversion_cast %64 : i64 to index\n",
       "        %66 = llvm.add %60, %3  : i64\n",
       "        %67 = builtin.unrealized_conversion_cast %66 : i64 to index\n",
       "        %68 = builtin.unrealized_conversion_cast %67 : index to i64\n",
       "        %69 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "        %70 = llvm.getelementptr %69[%68] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "        %71 = llvm.load %70 : !llvm.ptr<i64>\n",
       "        %72 = builtin.unrealized_conversion_cast %71 : i64 to index\n",
       "        %73 = scf.for %arg5 = %65 to %72 step %4 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %74 = builtin.unrealized_conversion_cast %arg5 : index to i64\n",
       "          %75 = llvm.extractvalue %19[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "          %76 = llvm.getelementptr %75[%74] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       "          %77 = llvm.load %76 : !llvm.ptr<f32>\n",
       "          %78 = llvm.fadd %arg6, %77  : f32\n",
       "          scf.yield %78 : f32\n",
       "        }\n",
       "        scf.yield %73 : f32\n",
       "      }\n",
       "      scf.yield %59 : f32\n",
       "    }\n",
       "    %43 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    llvm.store %42, %43 : !llvm.ptr<f32>\n",
       "    %44 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %45 = llvm.load %44 : !llvm.ptr<f32>\n",
       "    llvm.return %45 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "===================================\n",
       "  Input to convert-openmp-to-llvm  \n",
       "===================================\n",
       "module {\n",
       "  llvm.func @malloc(i64) -> !llvm.ptr<i8>\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %0 = builtin.unrealized_conversion_cast %c0 : index to i64\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %1 = builtin.unrealized_conversion_cast %c1 : index to i64\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %2 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = builtin.unrealized_conversion_cast %2 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %4 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %5 = builtin.unrealized_conversion_cast %4 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %6 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %7 = builtin.unrealized_conversion_cast %6 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %8 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %9 = builtin.unrealized_conversion_cast %8 : memref<?xf32> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %10 = llvm.mlir.constant(1 : index) : i64\n",
       "    %11 = llvm.mlir.null : !llvm.ptr<f32>\n",
       "    %12 = llvm.getelementptr %11[%10] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       "    %13 = llvm.ptrtoint %12 : !llvm.ptr<f32> to i64\n",
       "    %14 = llvm.call @malloc(%13) : (i64) -> !llvm.ptr<i8>\n",
       "    %15 = llvm.bitcast %14 : !llvm.ptr<i8> to !llvm.ptr<f32>\n",
       "    %16 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %17 = llvm.insertvalue %15, %16[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %18 = llvm.insertvalue %15, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %19 = llvm.mlir.constant(0 : index) : i64\n",
       "    %20 = llvm.insertvalue %19, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %21 = llvm.extractvalue %20[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    llvm.store %cst, %21 : !llvm.ptr<f32>\n",
       "    %22 = llvm.extractvalue %20[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %23 = llvm.load %22 : !llvm.ptr<f32>\n",
       "    %24 = llvm.extractvalue %3[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %25 = llvm.getelementptr %24[%0] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "    %26 = llvm.load %25 : !llvm.ptr<i64>\n",
       "    %27 = arith.index_cast %26 : i64 to index\n",
       "    %28 = llvm.extractvalue %3[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "    %29 = llvm.getelementptr %28[%1] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "    %30 = llvm.load %29 : !llvm.ptr<i64>\n",
       "    %31 = arith.index_cast %30 : i64 to index\n",
       "    %32 = scf.for %arg1 = %27 to %31 step %c1 iter_args(%arg2 = %23) -> (f32) {\n",
       "      %36 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
       "      %37 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "      %38 = llvm.getelementptr %37[%36] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "      %39 = llvm.load %38 : !llvm.ptr<i64>\n",
       "      %40 = arith.index_cast %39 : i64 to index\n",
       "      %41 = arith.addi %arg1, %c1 : index\n",
       "      %42 = builtin.unrealized_conversion_cast %41 : index to i64\n",
       "      %43 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "      %44 = llvm.getelementptr %43[%42] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "      %45 = llvm.load %44 : !llvm.ptr<i64>\n",
       "      %46 = arith.index_cast %45 : i64 to index\n",
       "      %47 = scf.for %arg3 = %40 to %46 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %48 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
       "        %49 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "        %50 = llvm.getelementptr %49[%48] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "        %51 = llvm.load %50 : !llvm.ptr<i64>\n",
       "        %52 = arith.index_cast %51 : i64 to index\n",
       "        %53 = arith.addi %arg3, %c1 : index\n",
       "        %54 = builtin.unrealized_conversion_cast %53 : index to i64\n",
       "        %55 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "        %56 = llvm.getelementptr %55[%54] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
       "        %57 = llvm.load %56 : !llvm.ptr<i64>\n",
       "        %58 = arith.index_cast %57 : i64 to index\n",
       "        %59 = scf.for %arg5 = %52 to %58 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %60 = builtin.unrealized_conversion_cast %arg5 : index to i64\n",
       "          %61 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
       "          %62 = llvm.getelementptr %61[%60] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
       "          %63 = llvm.load %62 : !llvm.ptr<f32>\n",
       "          %64 = arith.addf %arg6, %63 : f32\n",
       "          scf.yield %64 : f32\n",
       "        }\n",
       "        scf.yield %59 : f32\n",
       "      }\n",
       "      scf.yield %47 : f32\n",
       "    }\n",
       "    %33 = llvm.extractvalue %20[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    llvm.store %32, %33 : !llvm.ptr<f32>\n",
       "    %34 = llvm.extractvalue %20[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
       "    %35 = llvm.load %34 : !llvm.ptr<f32>\n",
       "    return %35 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "===================================\n",
       "  Input to convert-memref-to-llvm  \n",
       "===================================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    memref.store %cst, %4[] : memref<f32>\n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %12 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %13 = arith.index_cast %12 : i64 to index\n",
       "      %14 = arith.addi %arg1, %c1 : index\n",
       "      %15 = memref.load %1[%14] : memref<?xi64>\n",
       "      %16 = arith.index_cast %15 : i64 to index\n",
       "      %17 = scf.for %arg3 = %13 to %16 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %18 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %19 = arith.index_cast %18 : i64 to index\n",
       "        %20 = arith.addi %arg3, %c1 : index\n",
       "        %21 = memref.load %2[%20] : memref<?xi64>\n",
       "        %22 = arith.index_cast %21 : i64 to index\n",
       "        %23 = scf.for %arg5 = %19 to %22 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %24 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %25 = arith.addf %arg6, %24 : f32\n",
       "          scf.yield %25 : f32\n",
       "        }\n",
       "        scf.yield %23 : f32\n",
       "      }\n",
       "      scf.yield %17 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = memref.load %4[] : memref<f32>\n",
       "    return %11 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "=================================\n",
       "  Input to convert-math-to-libm  \n",
       "=================================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    memref.store %cst, %4[] : memref<f32>\n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %12 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %13 = arith.index_cast %12 : i64 to index\n",
       "      %14 = arith.addi %arg1, %c1 : index\n",
       "      %15 = memref.load %1[%14] : memref<?xi64>\n",
       "      %16 = arith.index_cast %15 : i64 to index\n",
       "      %17 = scf.for %arg3 = %13 to %16 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %18 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %19 = arith.index_cast %18 : i64 to index\n",
       "        %20 = arith.addi %arg3, %c1 : index\n",
       "        %21 = memref.load %2[%20] : memref<?xi64>\n",
       "        %22 = arith.index_cast %21 : i64 to index\n",
       "        %23 = scf.for %arg5 = %19 to %22 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %24 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %25 = arith.addf %arg6, %24 : f32\n",
       "          scf.yield %25 : f32\n",
       "        }\n",
       "        scf.yield %23 : f32\n",
       "      }\n",
       "      scf.yield %17 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = memref.load %4[] : memref<f32>\n",
       "    return %11 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "=================================\n",
       "  Input to convert-math-to-llvm  \n",
       "=================================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    memref.store %cst, %4[] : memref<f32>\n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %12 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %13 = arith.index_cast %12 : i64 to index\n",
       "      %14 = arith.addi %arg1, %c1 : index\n",
       "      %15 = memref.load %1[%14] : memref<?xi64>\n",
       "      %16 = arith.index_cast %15 : i64 to index\n",
       "      %17 = scf.for %arg3 = %13 to %16 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %18 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %19 = arith.index_cast %18 : i64 to index\n",
       "        %20 = arith.addi %arg3, %c1 : index\n",
       "        %21 = memref.load %2[%20] : memref<?xi64>\n",
       "        %22 = arith.index_cast %21 : i64 to index\n",
       "        %23 = scf.for %arg5 = %19 to %22 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %24 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %25 = arith.addf %arg6, %24 : f32\n",
       "          scf.yield %25 : f32\n",
       "        }\n",
       "        scf.yield %23 : f32\n",
       "      }\n",
       "      scf.yield %17 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = memref.load %4[] : memref<f32>\n",
       "    return %11 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "===================================\n",
       "  Input to convert-vector-to-llvm  \n",
       "===================================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    memref.store %cst, %4[] : memref<f32>\n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %12 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %13 = arith.index_cast %12 : i64 to index\n",
       "      %14 = arith.addi %arg1, %c1 : index\n",
       "      %15 = memref.load %1[%14] : memref<?xi64>\n",
       "      %16 = arith.index_cast %15 : i64 to index\n",
       "      %17 = scf.for %arg3 = %13 to %16 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %18 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %19 = arith.index_cast %18 : i64 to index\n",
       "        %20 = arith.addi %arg3, %c1 : index\n",
       "        %21 = memref.load %2[%20] : memref<?xi64>\n",
       "        %22 = arith.index_cast %21 : i64 to index\n",
       "        %23 = scf.for %arg5 = %19 to %22 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %24 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %25 = arith.addf %arg6, %24 : f32\n",
       "          scf.yield %25 : f32\n",
       "        }\n",
       "        scf.yield %23 : f32\n",
       "      }\n",
       "      scf.yield %17 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = memref.load %4[] : memref<f32>\n",
       "    return %11 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "====================================\n",
       "  Input to convert-linalg-to-loops  \n",
       "====================================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    linalg.fill(%cst, %4) : f32, memref<f32> \n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %12 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %13 = arith.index_cast %12 : i64 to index\n",
       "      %14 = arith.addi %arg1, %c1 : index\n",
       "      %15 = memref.load %1[%14] : memref<?xi64>\n",
       "      %16 = arith.index_cast %15 : i64 to index\n",
       "      %17 = scf.for %arg3 = %13 to %16 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %18 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %19 = arith.index_cast %18 : i64 to index\n",
       "        %20 = arith.addi %arg3, %c1 : index\n",
       "        %21 = memref.load %2[%20] : memref<?xi64>\n",
       "        %22 = arith.index_cast %21 : i64 to index\n",
       "        %23 = scf.for %arg5 = %19 to %22 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %24 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %25 = arith.addf %arg6, %24 : f32\n",
       "          scf.yield %25 : f32\n",
       "        }\n",
       "        scf.yield %23 : f32\n",
       "      }\n",
       "      scf.yield %17 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = memref.load %4[] : memref<f32>\n",
       "    return %11 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "=================================\n",
       "  Input to finalizing-bufferize  \n",
       "=================================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    linalg.fill(%cst, %4) : f32, memref<f32> \n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %12 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %13 = arith.index_cast %12 : i64 to index\n",
       "      %14 = arith.addi %arg1, %c1 : index\n",
       "      %15 = memref.load %1[%14] : memref<?xi64>\n",
       "      %16 = arith.index_cast %15 : i64 to index\n",
       "      %17 = scf.for %arg3 = %13 to %16 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %18 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %19 = arith.index_cast %18 : i64 to index\n",
       "        %20 = arith.addi %arg3, %c1 : index\n",
       "        %21 = memref.load %2[%20] : memref<?xi64>\n",
       "        %22 = arith.index_cast %21 : i64 to index\n",
       "        %23 = scf.for %arg5 = %19 to %22 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %24 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %25 = arith.addf %arg6, %24 : f32\n",
       "          scf.yield %25 : f32\n",
       "        }\n",
       "        scf.yield %23 : f32\n",
       "      }\n",
       "      scf.yield %17 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = memref.load %4[] : memref<f32>\n",
       "    return %11 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "=============================\n",
       "  Input to tensor-bufferize  \n",
       "=============================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    linalg.fill(%cst, %4) : f32, memref<f32> \n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %13 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %14 = arith.index_cast %13 : i64 to index\n",
       "      %15 = arith.addi %arg1, %c1 : index\n",
       "      %16 = memref.load %1[%15] : memref<?xi64>\n",
       "      %17 = arith.index_cast %16 : i64 to index\n",
       "      %18 = scf.for %arg3 = %14 to %17 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %19 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %20 = arith.index_cast %19 : i64 to index\n",
       "        %21 = arith.addi %arg3, %c1 : index\n",
       "        %22 = memref.load %2[%21] : memref<?xi64>\n",
       "        %23 = arith.index_cast %22 : i64 to index\n",
       "        %24 = scf.for %arg5 = %20 to %23 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %25 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %26 = arith.addf %arg6, %25 : f32\n",
       "          scf.yield %26 : f32\n",
       "        }\n",
       "        scf.yield %24 : f32\n",
       "      }\n",
       "      scf.yield %18 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = bufferization.to_tensor %4 : memref<f32>\n",
       "    %12 = tensor.extract %11[] : tensor<f32>\n",
       "    return %12 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "===========================\n",
       "  Input to func-bufferize  \n",
       "===========================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    linalg.fill(%cst, %4) : f32, memref<f32> \n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %13 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %14 = arith.index_cast %13 : i64 to index\n",
       "      %15 = arith.addi %arg1, %c1 : index\n",
       "      %16 = memref.load %1[%15] : memref<?xi64>\n",
       "      %17 = arith.index_cast %16 : i64 to index\n",
       "      %18 = scf.for %arg3 = %14 to %17 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %19 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %20 = arith.index_cast %19 : i64 to index\n",
       "        %21 = arith.addi %arg3, %c1 : index\n",
       "        %22 = memref.load %2[%21] : memref<?xi64>\n",
       "        %23 = arith.index_cast %22 : i64 to index\n",
       "        %24 = scf.for %arg5 = %20 to %23 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %25 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %26 = arith.addf %arg6, %25 : f32\n",
       "          scf.yield %26 : f32\n",
       "        }\n",
       "        scf.yield %24 : f32\n",
       "      }\n",
       "      scf.yield %18 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = bufferization.to_tensor %4 : memref<f32>\n",
       "    %12 = tensor.extract %11[] : tensor<f32>\n",
       "    return %12 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "============================\n",
       "  Input to arith-bufferize  \n",
       "============================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    linalg.fill(%cst, %4) : f32, memref<f32> \n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %13 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %14 = arith.index_cast %13 : i64 to index\n",
       "      %15 = arith.addi %arg1, %c1 : index\n",
       "      %16 = memref.load %1[%15] : memref<?xi64>\n",
       "      %17 = arith.index_cast %16 : i64 to index\n",
       "      %18 = scf.for %arg3 = %14 to %17 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %19 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %20 = arith.index_cast %19 : i64 to index\n",
       "        %21 = arith.addi %arg3, %c1 : index\n",
       "        %22 = memref.load %2[%21] : memref<?xi64>\n",
       "        %23 = arith.index_cast %22 : i64 to index\n",
       "        %24 = scf.for %arg5 = %20 to %23 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %25 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %26 = arith.addf %arg6, %25 : f32\n",
       "          scf.yield %26 : f32\n",
       "        }\n",
       "        scf.yield %24 : f32\n",
       "      }\n",
       "      scf.yield %18 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = bufferization.to_tensor %4 : memref<f32>\n",
       "    %12 = tensor.extract %11[] : tensor<f32>\n",
       "    return %12 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "=============================\n",
       "  Input to linalg-bufferize  \n",
       "=============================\n",
       "module {\n",
       "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
       "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
       "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
       "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    linalg.fill(%cst, %4) : f32, memref<f32> \n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %13 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %14 = arith.index_cast %13 : i64 to index\n",
       "      %15 = arith.addi %arg1, %c1 : index\n",
       "      %16 = memref.load %1[%15] : memref<?xi64>\n",
       "      %17 = arith.index_cast %16 : i64 to index\n",
       "      %18 = scf.for %arg3 = %14 to %17 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %19 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %20 = arith.index_cast %19 : i64 to index\n",
       "        %21 = arith.addi %arg3, %c1 : index\n",
       "        %22 = memref.load %2[%21] : memref<?xi64>\n",
       "        %23 = arith.index_cast %22 : i64 to index\n",
       "        %24 = scf.for %arg5 = %20 to %23 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %25 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %26 = arith.addf %arg6, %25 : f32\n",
       "          scf.yield %26 : f32\n",
       "        }\n",
       "        scf.yield %24 : f32\n",
       "      }\n",
       "      scf.yield %18 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = bufferization.to_tensor %4 : memref<f32>\n",
       "    %12 = tensor.extract %11[] : tensor<f32>\n",
       "    return %12 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "=====================================\n",
       "  Input to sparse-tensor-conversion  \n",
       "=====================================\n",
       "module {\n",
       "  func @func_f32(%arg0: tensor<10x20x30xf32, #sparse_tensor.encoding<{ dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ], dimOrdering = affine_map<(d0, d1, d2) -> (d0, d1, d2)>, pointerBitWidth = 64, indexBitWidth = 64 }>>) -> f32 {\n",
       "    %c0 = arith.constant 0 : index\n",
       "    %c1 = arith.constant 1 : index\n",
       "    %c2 = arith.constant 2 : index\n",
       "    %cst = arith.constant 0.000000e+00 : f32\n",
       "    %0 = sparse_tensor.pointers %arg0, %c0 : tensor<10x20x30xf32, #sparse_tensor.encoding<{ dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ], dimOrdering = affine_map<(d0, d1, d2) -> (d0, d1, d2)>, pointerBitWidth = 64, indexBitWidth = 64 }>> to memref<?xi64>\n",
       "    %1 = sparse_tensor.pointers %arg0, %c1 : tensor<10x20x30xf32, #sparse_tensor.encoding<{ dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ], dimOrdering = affine_map<(d0, d1, d2) -> (d0, d1, d2)>, pointerBitWidth = 64, indexBitWidth = 64 }>> to memref<?xi64>\n",
       "    %2 = sparse_tensor.pointers %arg0, %c2 : tensor<10x20x30xf32, #sparse_tensor.encoding<{ dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ], dimOrdering = affine_map<(d0, d1, d2) -> (d0, d1, d2)>, pointerBitWidth = 64, indexBitWidth = 64 }>> to memref<?xi64>\n",
       "    %3 = sparse_tensor.values %arg0 : tensor<10x20x30xf32, #sparse_tensor.encoding<{ dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ], dimOrdering = affine_map<(d0, d1, d2) -> (d0, d1, d2)>, pointerBitWidth = 64, indexBitWidth = 64 }>> to memref<?xf32>\n",
       "    %4 = memref.alloc() : memref<f32>\n",
       "    linalg.fill(%cst, %4) : f32, memref<f32> \n",
       "    %5 = memref.load %4[] : memref<f32>\n",
       "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
       "    %7 = arith.index_cast %6 : i64 to index\n",
       "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
       "    %9 = arith.index_cast %8 : i64 to index\n",
       "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
       "      %13 = memref.load %1[%arg1] : memref<?xi64>\n",
       "      %14 = arith.index_cast %13 : i64 to index\n",
       "      %15 = arith.addi %arg1, %c1 : index\n",
       "      %16 = memref.load %1[%15] : memref<?xi64>\n",
       "      %17 = arith.index_cast %16 : i64 to index\n",
       "      %18 = scf.for %arg3 = %14 to %17 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
       "        %19 = memref.load %2[%arg3] : memref<?xi64>\n",
       "        %20 = arith.index_cast %19 : i64 to index\n",
       "        %21 = arith.addi %arg3, %c1 : index\n",
       "        %22 = memref.load %2[%21] : memref<?xi64>\n",
       "        %23 = arith.index_cast %22 : i64 to index\n",
       "        %24 = scf.for %arg5 = %20 to %23 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
       "          %25 = memref.load %3[%arg5] : memref<?xf32>\n",
       "          %26 = arith.addf %arg6, %25 : f32\n",
       "          scf.yield %26 : f32\n",
       "        }\n",
       "        scf.yield %24 : f32\n",
       "      }\n",
       "      scf.yield %18 : f32\n",
       "    }\n",
       "    memref.store %10, %4[] : memref<f32>\n",
       "    %11 = bufferization.to_tensor %4 : memref<f32>\n",
       "    %12 = tensor.extract %11[] : tensor<f32>\n",
       "    return %12 : f32\n",
       "  }\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "===========================\n",
       "  Input to sparsification  \n",
       "===========================\n",
       "\n",
       "#trait_sum_reduction = {\n",
       "  indexing_maps = [\n",
       "    affine_map<(i,j,k) -> (i,j,k)>,  // A\n",
       "    affine_map<(i,j,k) -> ()>        // x (scalar out)\n",
       "  ],\n",
       "  iterator_types = [\"reduction\", \"reduction\", \"reduction\"],\n",
       "  doc = \"x += SUM_ijk A(i,j,k)\"\n",
       "}\n",
       "\n",
       "#sparseTensor = #sparse_tensor.encoding<{\n",
       "  dimLevelType = [ \"compressed\", \"compressed\", \"compressed\" ],\n",
       "  dimOrdering = affine_map<(i,j,k) -> (i,j,k)>,\n",
       "  pointerBitWidth = 64,\n",
       "  indexBitWidth = 64\n",
       "}>\n",
       "\n",
       "func @func_f32(%argA: tensor<10x20x30xf32, #sparseTensor>) -> f32 {\n",
       "  %out_tensor = linalg.init_tensor [] : tensor<f32>\n",
       "  %reduction = linalg.generic #trait_sum_reduction\n",
       "     ins(%argA: tensor<10x20x30xf32, #sparseTensor>)\n",
       "    outs(%out_tensor: tensor<f32>) {\n",
       "      ^bb(%a: f32, %x: f32):\n",
       "        %0 = arith.addf %x, %a : f32\n",
       "        linalg.yield %0 : f32\n",
       "  } -> tensor<f32>\n",
       "  %answer = tensor.extract %reduction[] : tensor<f32>\n",
       "  return %answer : f32\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-opinion",
   "metadata": {},
   "source": [
    "This large output may seem intimidating due to it's size, but it's mostly large since it's showing the inputs to each pass. \n",
    "\n",
    "We know that the error happens when the `builtin.unrealized_conversion_cast` operation occurs. \n",
    "\n",
    "We can see from the output above that it happens during the `convert-std-to-llvm` pass. \n",
    "\n",
    "It's likely that there's something problematic in the input to that pass, so it's worth looking into the IR that was given to the `convert-std-to-llvm` pass, which we can see under the section labelled `\n",
    "`. We'll show a sort snippet of it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b0cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "  Input to convert-std-to-llvm  \n",
      "================================\n",
      "module {\n",
      "  llvm.func @malloc(i64) -> !llvm.ptr<i8>\n",
      "  llvm.func @sparseValuesF32(%arg0: !llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
      "    %0 = llvm.mlir.constant(1 : index) : i64\n",
      "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
      "    llvm.call @_mlir_ciface_sparseValuesF32(%1, %arg0) : (!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) -> ()\n",
      "    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
      "    llvm.return %2 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "  }\n",
      "  llvm.func @_mlir_ciface_sparseValuesF32(!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
      "  llvm.func @sparsePointers64(%arg0: !llvm.ptr<i8>, %arg1: i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
      "    %0 = llvm.mlir.constant(1 : index) : i64\n",
      "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
      "    llvm.call @_mlir_ciface_sparsePointers64(%1, %arg0, %arg1) : (!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) -> ()\n",
      "    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
      "    llvm.return %2 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "  }\n",
      "  llvm.func @_mlir_ciface_sparsePointers64(!llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>, i64) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
      "  llvm.func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
      "    %0 = llvm.mlir.constant(0 : index) : i64\n",
      "    %1 = builtin.unrealized_conversion_cast %0 : i64 to index\n",
      "    %2 = builtin.unrealized_conversion_cast %1 : index to i64\n",
      "    %3 = llvm.mlir.constant(1 : index) : i64\n",
      "    %4 = builtin.unrealized_conversion_cast %3 : i64 to index\n",
      "    %5 = builtin.unrealized_conversion_cast %4 : index to i64\n",
      "    %6 = llvm.mlir.constant(2 : index) : i64\n",
      "    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32\n",
      "    %8 = llvm.call @sparsePointers64(%arg0, %0) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %9 = builtin.unrealized_conversion_cast %8 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
      "    %10 = builtin.unrealized_conversion_cast %9 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %11 = llvm.call @sparsePointers64(%arg0, %3) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %12 = builtin.unrealized_conversion_cast %11 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
      "    %13 = builtin.unrealized_conversion_cast %12 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %14 = llvm.call @sparsePointers64(%arg0, %6) : (!llvm.ptr<i8>, i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xi64>\n",
      "    %16 = builtin.unrealized_conversion_cast %15 : memref<?xi64> to !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %17 = llvm.call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>\n",
      "    %19 = builtin.unrealized_conversion_cast %18 : memref<?xf32> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %20 = llvm.mlir.constant(1 : index) : i64\n",
      "    %21 = llvm.mlir.null : !llvm.ptr<f32>\n",
      "    %22 = llvm.getelementptr %21[%20] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
      "    %23 = llvm.ptrtoint %22 : !llvm.ptr<f32> to i64\n",
      "    %24 = llvm.call @malloc(%23) : (i64) -> !llvm.ptr<i8>\n",
      "    %25 = llvm.bitcast %24 : !llvm.ptr<i8> to !llvm.ptr<f32>\n",
      "    %26 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    %27 = llvm.insertvalue %25, %26[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    %28 = llvm.insertvalue %25, %27[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    %29 = llvm.mlir.constant(0 : index) : i64\n",
      "    %30 = llvm.insertvalue %29, %28[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    %31 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    llvm.store %7, %31 : !llvm.ptr<f32>\n",
      "    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    %33 = llvm.load %32 : !llvm.ptr<f32>\n",
      "    %34 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %35 = llvm.getelementptr %34[%2] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
      "    %36 = llvm.load %35 : !llvm.ptr<i64>\n",
      "    %37 = builtin.unrealized_conversion_cast %36 : i64 to index\n",
      "    %38 = llvm.extractvalue %10[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "    %39 = llvm.getelementptr %38[%5] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
      "    %40 = llvm.load %39 : !llvm.ptr<i64>\n",
      "    %41 = builtin.unrealized_conversion_cast %40 : i64 to index\n",
      "    %42 = scf.for %arg1 = %37 to %41 step %4 iter_args(%arg2 = %33) -> (f32) {\n",
      "      %46 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
      "      %47 = builtin.unrealized_conversion_cast %arg1 : index to i64\n",
      "      %48 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "      %49 = llvm.getelementptr %48[%47] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
      "      %50 = llvm.load %49 : !llvm.ptr<i64>\n",
      "      %51 = builtin.unrealized_conversion_cast %50 : i64 to index\n",
      "      %52 = llvm.add %46, %3  : i64\n",
      "      %53 = builtin.unrealized_conversion_cast %52 : i64 to index\n",
      "      %54 = builtin.unrealized_conversion_cast %53 : index to i64\n",
      "      %55 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "      %56 = llvm.getelementptr %55[%54] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
      "      %57 = llvm.load %56 : !llvm.ptr<i64>\n",
      "      %58 = builtin.unrealized_conversion_cast %57 : i64 to index\n",
      "      %59 = scf.for %arg3 = %51 to %58 step %4 iter_args(%arg4 = %arg2) -> (f32) {\n",
      "        %60 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
      "        %61 = builtin.unrealized_conversion_cast %arg3 : index to i64\n",
      "        %62 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "        %63 = llvm.getelementptr %62[%61] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
      "        %64 = llvm.load %63 : !llvm.ptr<i64>\n",
      "        %65 = builtin.unrealized_conversion_cast %64 : i64 to index\n",
      "        %66 = llvm.add %60, %3  : i64\n",
      "        %67 = builtin.unrealized_conversion_cast %66 : i64 to index\n",
      "        %68 = builtin.unrealized_conversion_cast %67 : index to i64\n",
      "        %69 = llvm.extractvalue %16[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "        %70 = llvm.getelementptr %69[%68] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>\n",
      "        %71 = llvm.load %70 : !llvm.ptr<i64>\n",
      "        %72 = builtin.unrealized_conversion_cast %71 : i64 to index\n",
      "        %73 = scf.for %arg5 = %65 to %72 step %4 iter_args(%arg6 = %arg4) -> (f32) {\n",
      "          %74 = builtin.unrealized_conversion_cast %arg5 : index to i64\n",
      "          %75 = llvm.extractvalue %19[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "          %76 = llvm.getelementptr %75[%74] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>\n",
      "          %77 = llvm.load %76 : !llvm.ptr<f32>\n",
      "          %78 = llvm.fadd %arg6, %77  : f32\n",
      "          scf.yield %78 : f32\n",
      "        }\n",
      "        scf.yield %73 : f32\n",
      "      }\n",
      "      scf.yield %59 : f32\n",
      "    }\n",
      "    %43 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    llvm.store %42, %43 : !llvm.ptr<f32>\n",
      "    %44 = llvm.extractvalue %30[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64)>\n",
      "    %45 = llvm.load %44 : !llvm.ptr<f32>\n",
      "    llvm.return %45 : f32\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result_string = str(result)\n",
    "lines = result_string.splitlines()\n",
    "lines = lines[lines.index(\"  Input to convert-std-to-llvm  \")-1:]\n",
    "lines = lines[:lines.index(\"\")]\n",
    "print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ace11",
   "metadata": {},
   "source": [
    "While this is a good idea in general, it doesn't seem to be useful here. When MLIR applies a pass, that pass is applied until quiescence, i.e. it keeps applying the pass until nothing changes (or until some limit on the number of applications is reached). \n",
    "\n",
    "It seems that the `convert-std-to-llvm` pass has already been applied a few times since we see several ops from the LLVM dialect already present in the IR shown under the `Input to convert-std-to-llvm` section (for example, we see `llvm.mlir.constant`). \n",
    "\n",
    "Another good place to look is in the output of the last pass right before we get our error. Let's look at the result of the `convert-math-to-llvm` pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363d28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "  Input to convert-math-to-llvm  \n",
      "=================================\n",
      "module {\n",
      "  func private @sparseValuesF32(!llvm.ptr<i8>) -> memref<?xf32> attributes {llvm.emit_c_interface}\n",
      "  func private @sparsePointers64(!llvm.ptr<i8>, index) -> memref<?xi64> attributes {llvm.emit_c_interface}\n",
      "  func @func_f32(%arg0: !llvm.ptr<i8>) -> f32 {\n",
      "    %c0 = arith.constant 0 : index\n",
      "    %c1 = arith.constant 1 : index\n",
      "    %c2 = arith.constant 2 : index\n",
      "    %cst = arith.constant 0.000000e+00 : f32\n",
      "    %0 = call @sparsePointers64(%arg0, %c0) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
      "    %1 = call @sparsePointers64(%arg0, %c1) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
      "    %2 = call @sparsePointers64(%arg0, %c2) : (!llvm.ptr<i8>, index) -> memref<?xi64>\n",
      "    %3 = call @sparseValuesF32(%arg0) : (!llvm.ptr<i8>) -> memref<?xf32>\n",
      "    %4 = memref.alloc() : memref<f32>\n",
      "    memref.store %cst, %4[] : memref<f32>\n",
      "    %5 = memref.load %4[] : memref<f32>\n",
      "    %6 = memref.load %0[%c0] : memref<?xi64>\n",
      "    %7 = arith.index_cast %6 : i64 to index\n",
      "    %8 = memref.load %0[%c1] : memref<?xi64>\n",
      "    %9 = arith.index_cast %8 : i64 to index\n",
      "    %10 = scf.for %arg1 = %7 to %9 step %c1 iter_args(%arg2 = %5) -> (f32) {\n",
      "      %12 = memref.load %1[%arg1] : memref<?xi64>\n",
      "      %13 = arith.index_cast %12 : i64 to index\n",
      "      %14 = arith.addi %arg1, %c1 : index\n",
      "      %15 = memref.load %1[%14] : memref<?xi64>\n",
      "      %16 = arith.index_cast %15 : i64 to index\n",
      "      %17 = scf.for %arg3 = %13 to %16 step %c1 iter_args(%arg4 = %arg2) -> (f32) {\n",
      "        %18 = memref.load %2[%arg3] : memref<?xi64>\n",
      "        %19 = arith.index_cast %18 : i64 to index\n",
      "        %20 = arith.addi %arg3, %c1 : index\n",
      "        %21 = memref.load %2[%20] : memref<?xi64>\n",
      "        %22 = arith.index_cast %21 : i64 to index\n",
      "        %23 = scf.for %arg5 = %19 to %22 step %c1 iter_args(%arg6 = %arg4) -> (f32) {\n",
      "          %24 = memref.load %3[%arg5] : memref<?xf32>\n",
      "          %25 = arith.addf %arg6, %24 : f32\n",
      "          scf.yield %25 : f32\n",
      "        }\n",
      "        scf.yield %23 : f32\n",
      "      }\n",
      "      scf.yield %17 : f32\n",
      "    }\n",
      "    memref.store %10, %4[] : memref<f32>\n",
      "    %11 = memref.load %4[] : memref<f32>\n",
      "    return %11 : f32\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "lines = result_string.splitlines()\n",
    "lines = lines[lines.index(\"  Input to convert-math-to-llvm  \")-1:]\n",
    "lines = lines[:lines.index(\"\")]\n",
    "print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee2493",
   "metadata": {},
   "source": [
    "We see that the ops are mostly ops from the standard, llvm, and builtin dialects. However, there are some ops from the `scf` dialect. It would make sense that the `convert-std-to-llvm` pass would be able to handle ops from the builtin dialect. It would make sense that it be able to handle ops from the llvm dialect since that's the target diallect. It's unclear whether or not the `convert-std-to-llvm` dialect can handle ops from the `scf` dialect. Given the name of the `convert-std-to-llvm` pass, we can infer that it will mostly handle ops from the `std` dialect and cannot handle ops from the `scf` dialect. Let's see if there are any passes that can convert from the `scf` dialect to the `std` dialect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de378332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Dialects: acc, affine, amx, arith, arm_neon, arm_sve, async, bufferization, builtin, cf, complex, dlti, emitc, gpu, linalg, llvm, math, memref, nvvm, omp, pdl, pdl_interp, quant, rocdl, scf, shape, sparse_tensor, spv, std, tensor, test, tosa, vector, x86vector\r\n",
      "      --async-parallel-for                              -   Convert scf.parallel operations to multiple async compute ops executed concurrently for non-overlapping iteration ranges\r\n",
      "      --convert-linalg-tiled-loops-to-scf               -   Lower linalg tiled loops to SCF loops and parallel loops\r\n",
      "      --convert-openacc-to-scf                          -   Convert the OpenACC ops to OpenACC with SCF dialect\r\n",
      "      --convert-parallel-loops-to-gpu                   -   Convert mapped scf.parallel ops to gpu launch operations\r\n",
      "      --convert-scf-to-cf                               -   Convert SCF dialect to ControlFlow dialect, replacing structured control flow with a CFG\r\n",
      "      --convert-scf-to-openmp                           -   Convert SCF parallel loop to OpenMP parallel + workshare constructs.\r\n",
      "      --convert-scf-to-spirv                            -   Convert SCF dialect to SPIR-V dialect.\r\n",
      "      --convert-vector-to-scf                           -   Lower the operations from the vector dialect into the SCF dialect\r\n",
      "      --scf-bufferize                                   -   Bufferize the scf dialect.\r\n",
      "      --scf-for-loop-canonicalization                   -   Canonicalize operations within scf.for loop bodies\r\n",
      "      --scf-for-loop-peeling                            -   Peel `for` loops at their upper bounds.\r\n",
      "      --scf-for-loop-range-folding                      -   Fold add/mul ops into loop range\r\n",
      "      --scf-for-loop-specialization                     -   Specialize `for` loops for vectorization\r\n",
      "      --scf-for-to-while                                -   Convert SCF for loops to SCF while loops\r\n",
      "      --scf-parallel-loop-collapsing                    -   Collapse parallel loops to use less induction variables\r\n",
      "      --scf-parallel-loop-fusion                        -   Fuse adjacent parallel loops\r\n",
      "      --scf-parallel-loop-specialization                -   Specialize parallel loops for vectorization\r\n",
      "      --scf-parallel-loop-tiling                        -   Tile parallel loops\r\n",
      "      --test-scf-for-utils                              -   test scf.for utils\r\n",
      "      --test-scf-if-utils                               -   test scf.if utils\r\n",
      "      --test-scf-pipelining                             -   test scf.forOp pipelining\r\n",
      "      --test-vector-transfer-full-partial-split         -   Test lowering patterns to split transfer ops via scf.if + linalg ops\r\n",
      "      --tosa-to-scf                                     -   Lower TOSA to the SCF dialect\r\n"
     ]
    }
   ],
   "source": [
    "!mlir-opt --help | grep \"scf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-round",
   "metadata": {},
   "source": [
    "The pass `convert-scf-to-cf` seems promising as it intends to convert the `scf` dialect to `cf` dialect. \n",
    "\n",
    "Let's see if running the `convert-scf-to-cf` pass any of the conversion passes will get rid of our exception. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ideal-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module attributes {llvm.data_layout = \"\"} {\n",
      "  llvm.func @malloc(i64) -> !llvm.ptr<i8>\n",
      "  llvm.func @sparseValuesF32(%arg0: !llvm.ptr<i8>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
      "    %0 = llvm.mlir.constant(1 : index) : i64\n",
      "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
      "    llvm.call @_mlir_ciface_sparseValuesF32(%1, %arg0) : (!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) -> ()\n",
      "    %2 = llvm.load %1 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>\n",
      "    llvm.return %2 : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>\n",
      "  }\n",
      "  llvm.func @_mlir_ciface_sparseValuesF32(!llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>>, !llvm.ptr<i8>) attributes {llvm.emit_c_interface, sym_visibility = \"private\"}\n",
      "  llvm.func @sparsePointers64(%arg0: !llvm.ptr<i8>, %arg1: i64) -> !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> attributes {llvm.emit_c_interface, sym_visibility = \"private\"} {\n",
      "    %0 = llvm.mlir.constant(1 : index) : i64\n",
      "    %1 = llvm.alloca %0 x !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> : (i64) -> !llvm.ptr<struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "passes = [\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--arith-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-scf-to-cf\", # newly added\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-vector-to-llvm\",\n",
    "    \"--convert-math-to-llvm\",\n",
    "    \"--convert-math-to-libm\",\n",
    "    \"--convert-memref-to-llvm\",\n",
    "    \"--convert-openmp-to-llvm\",\n",
    "    \"--convert-arith-to-llvm\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "    \"--reconcile-unrealized-casts\"\n",
    "]\n",
    "result = cli.apply_passes(mlir_bytes, passes)\n",
    "print(result[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-parks",
   "metadata": {},
   "source": [
    "It looks like it fixed our issue!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
