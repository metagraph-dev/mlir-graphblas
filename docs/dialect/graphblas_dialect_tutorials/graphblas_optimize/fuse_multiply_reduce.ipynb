{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ea7794",
   "metadata": {},
   "source": [
    "# Fusing graphblas.matrix_multiply with graphblas.reduce_to_scalar_generic\n",
    "\n",
    "This example will go over how to use the `--graphblas-structuralize` and `--graphblas-optimize` passes from `graphblas-opt` to fuse `graphblas.matrix_multiply` ops with `graphblas.reduce_to_scalar` ops into `graphblas.matrix_multiply_reduce_to_scalar_generic` ops.\n",
    "\n",
    "Let's first import some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6dfc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from mlir_graphblas.cli import GRAPHBLAS_OPT_EXE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef189e",
   "metadata": {},
   "source": [
    "Since [sparse tensor encodings](https://mlir.llvm.org/docs/Dialects/SparseTensorOps/#sparsetensorencodingattr) can be very verbose in MLIR, let's import some helpers to make the MLIR code more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4233b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlir_graphblas.tools import tersify_mlir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db75a69",
   "metadata": {},
   "source": [
    "## Simple Fusion\n",
    "\n",
    "Here, we'll show the simplest example of how we can fuse a `graphblas.matrix_multiply` op with a `graphblas.reduce_to_scalar` op into a `graphblas.matrix_multiply_reduce_to_scalar_generic` op. Note that this requires using the `--graphblas-structuralize` pass prior to using the `--graphblas-optimize` pass so that the code can be in a state optimizable by the `--graphblas-optimize` pass. In partcular, we need all `graphblas.reduce_to_scalar` ops lowered into `graphblas.reduce_to_scalar_generic` ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a6fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CSC64 = #sparse_tensor.encoding<{ \n",
      "    dimLevelType = [ \"dense\", \"compressed\" ], \n",
      "    dimOrdering = affine_map<(d0, d1) -> (d1, d0)>, \n",
      "    pointerBitWidth = 64, \n",
      "    indexBitWidth = 64 \n",
      "}>\n",
      "\n",
      "#CSR64 = #sparse_tensor.encoding<{ \n",
      "    dimLevelType = [ \"dense\", \"compressed\" ], \n",
      "    dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, \n",
      "    pointerBitWidth = 64, \n",
      "    indexBitWidth = 64 \n",
      "}>\n",
      "\n",
      "builtin.module  {\n",
      "  builtin.func @fuse_adjacent(%arg0: tensor<?x?xf64, #CSR64>, %arg1: tensor<?x?xf64, #CSC64>) -> f64 {\n",
      "    %cst = constant 0.000000e+00 : f64\n",
      "    %0 = graphblas.matrix_multiply_reduce_to_scalar_generic %arg0, %arg1 {mask_complement = false} : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to f64  {\n",
      "      graphblas.yield add_identity %cst : f64\n",
      "    },  {\n",
      "    ^bb0(%arg2: f64, %arg3: f64):  // no predecessors\n",
      "      %1 = addf %arg2, %arg3 : f64\n",
      "      graphblas.yield add %1 : f64\n",
      "    },  {\n",
      "    ^bb0(%arg2: f64, %arg3: f64):  // no predecessors\n",
      "      %1 = addf %arg2, %arg3 : f64\n",
      "      graphblas.yield mult %1 : f64\n",
      "    },  {\n",
      "      graphblas.yield agg_identity %cst : f64\n",
      "    },  {\n",
      "    ^bb0(%arg2: f64, %arg3: f64):  // no predecessors\n",
      "      %1 = addf %arg2, %arg3 : f64\n",
      "      graphblas.yield agg %1 : f64\n",
      "    }\n",
      "    return %0 : f64\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @fuse_adjacent(%A: tensor<?x?xf64, #CSR64>, %B: tensor<?x?xf64, #CSC64>) -> f64 {\n",
    "    %C = graphblas.matrix_multiply %A, %B { semiring = \"plus_plus\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64> \n",
    "    %reduce_result = graphblas.reduce_to_scalar %C { aggregator = \"plus\" } : tensor<?x?xf64, #CSR64> to f64\n",
    "    return %reduce_result : f64\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(mlir_text)\n",
    "    temp.flush()\n",
    "\n",
    "    output_mlir = ! cat $temp_file_name | $GRAPHBLAS_OPT_EXE --graphblas-structuralize --graphblas-optimize\n",
    "    output_mlir = \"\\n\".join(output_mlir)\n",
    "    output_mlir = tersify_mlir(output_mlir)\n",
    "\n",
    "print(output_mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db32140",
   "metadata": {},
   "source": [
    "## Simple Fusion with Mask\n",
    "\n",
    "Fusion of `graphblas.matrix_multiply` ops with `graphblas.reduce_to_scalar` ops also works if the `graphblas.matrix_multiply` use takes a mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b54ca16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CSC64 = #sparse_tensor.encoding<{ \n",
      "    dimLevelType = [ \"dense\", \"compressed\" ], \n",
      "    dimOrdering = affine_map<(d0, d1) -> (d1, d0)>, \n",
      "    pointerBitWidth = 64, \n",
      "    indexBitWidth = 64 \n",
      "}>\n",
      "\n",
      "#CSR64 = #sparse_tensor.encoding<{ \n",
      "    dimLevelType = [ \"dense\", \"compressed\" ], \n",
      "    dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, \n",
      "    pointerBitWidth = 64, \n",
      "    indexBitWidth = 64 \n",
      "}>\n",
      "\n",
      "builtin.module  {\n",
      "  builtin.func @fuse_adjacent_with_mask(%arg0: tensor<?x?xf64, #CSR64>, %arg1: tensor<?x?xf64, #CSC64>, %arg2: tensor<?x?xf64, #CSR64>) -> f64 {\n",
      "    %cst = constant 1.000000e+00 : f64\n",
      "    %cst_0 = constant 0.000000e+00 : f64\n",
      "    %0 = graphblas.matrix_multiply_reduce_to_scalar_generic %arg0, %arg1, %arg2 {mask_complement = false} : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>, tensor<?x?xf64, #CSR64>) to f64  {\n",
      "      graphblas.yield add_identity %cst_0 : f64\n",
      "    },  {\n",
      "    ^bb0(%arg3: f64, %arg4: f64):  // no predecessors\n",
      "      %1 = addf %arg3, %arg4 : f64\n",
      "      graphblas.yield add %1 : f64\n",
      "    },  {\n",
      "    ^bb0(%arg3: f64, %arg4: f64):  // no predecessors\n",
      "      graphblas.yield mult %cst : f64\n",
      "    },  {\n",
      "      graphblas.yield agg_identity %cst_0 : f64\n",
      "    },  {\n",
      "    ^bb0(%arg3: f64, %arg4: f64):  // no predecessors\n",
      "      %1 = addf %arg3, %arg4 : f64\n",
      "      graphblas.yield agg %1 : f64\n",
      "    }\n",
      "    return %0 : f64\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @fuse_adjacent_with_mask(%A: tensor<?x?xf64, #CSR64>, %B: tensor<?x?xf64, #CSC64>, %mask: tensor<?x?xf64, #CSR64>) -> f64 {\n",
    "    %C = graphblas.matrix_multiply %A, %B, %mask { semiring = \"plus_pair\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>, tensor<?x?xf64, #CSR64>) to tensor<?x?xf64, #CSR64> \n",
    "    %reduce_result = graphblas.reduce_to_scalar %C { aggregator = \"plus\" } : tensor<?x?xf64, #CSR64> to f64\n",
    "    return %reduce_result : f64\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(mlir_text)\n",
    "    temp.flush()\n",
    "\n",
    "    output_mlir = ! cat $temp_file_name | $GRAPHBLAS_OPT_EXE --graphblas-structuralize --graphblas-optimize\n",
    "    output_mlir = \"\\n\".join(output_mlir)\n",
    "    output_mlir = tersify_mlir(output_mlir)\n",
    "\n",
    "print(output_mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455605d",
   "metadata": {},
   "source": [
    "## Non-applicable Fusion\n",
    "\n",
    "One thing to note is that if the result of any intermediate values of the ops being fused, e.g. the result of a `graphblas.matrix_multiply`, is used elsewhere, the fusion cannot and will not apply as shown here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f41637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CSC64 = #sparse_tensor.encoding<{ \n",
      "    dimLevelType = [ \"dense\", \"compressed\" ], \n",
      "    dimOrdering = affine_map<(d0, d1) -> (d1, d0)>, \n",
      "    pointerBitWidth = 64, \n",
      "    indexBitWidth = 64 \n",
      "}>\n",
      "\n",
      "#CSR64 = #sparse_tensor.encoding<{ \n",
      "    dimLevelType = [ \"dense\", \"compressed\" ], \n",
      "    dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, \n",
      "    pointerBitWidth = 64, \n",
      "    indexBitWidth = 64 \n",
      "}>\n",
      "\n",
      "builtin.module  {\n",
      "  builtin.func @nofuse_multi_use(%arg0: tensor<?x?xf64, #CSR64>, %arg1: tensor<?x?xf64, #CSC64>) -> (f64, tensor<?x?xf64, #CSR64>) {\n",
      "    %cst = constant 0.000000e+00 : f64\n",
      "    %0 = graphblas.matrix_multiply_generic %arg0, %arg1 {mask_complement = false} : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>  {\n",
      "      graphblas.yield add_identity %cst : f64\n",
      "    },  {\n",
      "    ^bb0(%arg2: f64, %arg3: f64):  // no predecessors\n",
      "      %2 = addf %arg2, %arg3 : f64\n",
      "      graphblas.yield add %2 : f64\n",
      "    },  {\n",
      "    ^bb0(%arg2: f64, %arg3: f64):  // no predecessors\n",
      "      %2 = addf %arg2, %arg3 : f64\n",
      "      graphblas.yield mult %2 : f64\n",
      "    }\n",
      "    %1 = graphblas.reduce_to_scalar_generic %0 : tensor<?x?xf64, #CSR64> to f64  {\n",
      "      graphblas.yield agg_identity %cst : f64\n",
      "    },  {\n",
      "    ^bb0(%arg2: f64, %arg3: f64):  // no predecessors\n",
      "      %2 = addf %arg2, %arg3 : f64\n",
      "      graphblas.yield agg %2 : f64\n",
      "    }\n",
      "    return %1, %0 : f64, tensor<?x?xf64, #CSR64>\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @nofuse_multi_use(%A: tensor<?x?xf64, #CSR64>, %B: tensor<?x?xf64, #CSC64>) -> (f64, tensor<?x?xf64, #CSR64>) {\n",
    "    %C = graphblas.matrix_multiply %A, %B { semiring = \"plus_plus\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64> \n",
    "    %reduce_result = graphblas.reduce_to_scalar %C { aggregator = \"plus\" } : tensor<?x?xf64, #CSR64> to f64\n",
    "    return %reduce_result, %C : f64, tensor<?x?xf64, #CSR64>\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(mlir_text)\n",
    "    temp.flush()\n",
    "\n",
    "    output_mlir = ! cat $temp_file_name | $GRAPHBLAS_OPT_EXE --graphblas-structuralize --graphblas-optimize\n",
    "    output_mlir = \"\\n\".join(output_mlir)\n",
    "    output_mlir = tersify_mlir(output_mlir)\n",
    "\n",
    "print(output_mlir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
