{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e37bc79",
   "metadata": {},
   "source": [
    "# Python Utilities for MLIR's Sparse Tensors\n",
    "\n",
    "Before going into actual examples, we'll first go over some useful utilities for working with MLIR's sparse tensors in Python.\n",
    "\n",
    "Letâ€™s first import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e07aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir_graphblas\n",
    "from mlir_graphblas.sparse_utils import MLIRSparseTensor\n",
    "from mlir_graphblas.cli import GRAPHBLAS_OPT_EXE\n",
    "from mlir_graphblas.tools import tersify_mlir\n",
    "from mlir_graphblas.tools.utils import sparsify_array, densify_csr, densify_csc, densify_vector\n",
    "\n",
    "import tempfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f983c1f",
   "metadata": {},
   "source": [
    "The first useful thing to note is that `GRAPHBLAS_OPT_EXE` from `mlir_graphblas.cli` holds the location of the locally used `graphblas-opt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d6717",
   "metadata": {},
   "source": [
    "## Overview of `tersify_mlir`\n",
    "\n",
    "When MLIR code is passed through `graphblas-opt` or `mlir-opt`, it can often become more verbose or difficult to read. This is true when using sparse tensors due to [sparse tensor encodings](https://mlir.llvm.org/docs/Dialects/SparseTensorOps/#sparsetensorencodingattr). \n",
    "\n",
    "For example, this code is fairly easy to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e61f3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @mat_mul(%argA: tensor<?x?xf64, #CSR64>, %argB: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
    "    %answer = graphblas.matrix_multiply %argA, %argB { semiring = \"plus_times\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>\n",
    "    return %answer : tensor<?x?xf64, #CSR64>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de30e6",
   "metadata": {},
   "source": [
    "However, when passing it through `graphblas-opt` or `mlir-opt` with no passes (which will produce behaviorally identical code), the [aliases](https://mlir.llvm.org/docs/LangRef/#attribute-value-aliases) for the [sparse tensor encodings](https://mlir.llvm.org/docs/Dialects/SparseTensorOps/#sparsetensorencodingattr) get expanded and results in very verbose code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98547128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builtin.module  {\n",
      "  builtin.func @mat_mul(%arg0: tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, %arg1: tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d1, d0)>, pointerBitWidth = 64, indexBitWidth = 64 }>>) -> tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>> {\n",
      "    %0 = graphblas.matrix_multiply %arg0, %arg1 {semiring = \"plus_times\"} : (tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d1, d0)>, pointerBitWidth = 64, indexBitWidth = 64 }>>) to tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>\n",
      "    return %0 : tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(mlir_text)\n",
    "    temp.flush()\n",
    "\n",
    "    verbose_mlir = ! cat $temp_file_name | $GRAPHBLAS_OPT_EXE\n",
    "    verbose_mlir = \"\\n\".join(verbose_mlir)\n",
    "\n",
    "print(verbose_mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196aa33a",
   "metadata": {},
   "source": [
    "We can make this resulting code less verbose and more readable using `tersify_mlir` from `mlir_graphblas.tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6522f8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CSR64 = #sparse_tensor.encoding<{\n",
      "    dimLevelType = [ \"dense\", \"compressed\" ],\n",
      "    dimOrdering = affine_map<(d0, d1) -> (d0, d1)>,\n",
      "    pointerBitWidth = 64,\n",
      "    indexBitWidth = 64\n",
      "}>\n",
      "\n",
      "#CSC64 = #sparse_tensor.encoding<{\n",
      "    dimLevelType = [ \"dense\", \"compressed\" ],\n",
      "    dimOrdering = affine_map<(d0, d1) -> (d1, d0)>,\n",
      "    pointerBitWidth = 64,\n",
      "    indexBitWidth = 64\n",
      "}>\n",
      "\n",
      "builtin.module  {\n",
      "  builtin.func @mat_mul(%arg0: tensor<?x?xf64, #CSR64>, %arg1: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
      "    %0 = graphblas.matrix_multiply %arg0, %arg1 {semiring = \"plus_times\"} : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>\n",
      "    return %0 : tensor<?x?xf64, #CSR64>\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tersify_mlir(verbose_mlir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1d009",
   "metadata": {},
   "source": [
    "`tersify_mlir` mostly moves [sparse tensor encodings](https://mlir.llvm.org/docs/Dialects/SparseTensorOps/#sparsetensorencodingattr) commonly used in the GraphBLAS dialect (i.e. the CSR, CSC, and compressed vector encodings) to [aliases](https://mlir.llvm.org/docs/LangRef/#attribute-value-aliases).\n",
    "\n",
    "`tersify_mlir` is also available as a tool to be used at the command line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e52e0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CSR64 = #sparse_tensor.encoding<{\n",
      "    dimLevelType = [ \"dense\", \"compressed\" ],\n",
      "    dimOrdering = affine_map<(d0, d1) -> (d0, d1)>,\n",
      "    pointerBitWidth = 64,\n",
      "    indexBitWidth = 64\n",
      "}>\n",
      "\n",
      "#CSC64 = #sparse_tensor.encoding<{\n",
      "    dimLevelType = [ \"dense\", \"compressed\" ],\n",
      "    dimOrdering = affine_map<(d0, d1) -> (d1, d0)>,\n",
      "    pointerBitWidth = 64,\n",
      "    indexBitWidth = 64\n",
      "}>\n",
      "\n",
      "builtin.module  {\n",
      "  builtin.func @mat_mul(%arg0: tensor<?x?xf64, #CSR64>, %arg1: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
      "    %0 = graphblas.matrix_multiply %arg0, %arg1 {semiring = \"plus_times\"} : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>\n",
      "    return %0 : tensor<?x?xf64, #CSR64>\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(verbose_mlir)\n",
    "    temp.flush()\n",
    "\n",
    "    terse_mlir_via_command_line = ! cat $temp_file_name | tersify_mlir 2> /dev/null\n",
    "    terse_mlir_via_command_line = \"\\n\".join(terse_mlir_via_command_line)\n",
    "\n",
    "print(terse_mlir_via_command_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb024b0",
   "metadata": {},
   "source": [
    "## Overview of `sparsify_array`\n",
    "\n",
    "Very often when debugging or testing, it is useful to convert a dense tensor represented as an array in [NumPy](https://numpy.org/). \n",
    "\n",
    "`sparsify_array` from `mlir_graphblas.tools.utils` let's us do that. \n",
    "\n",
    "Let's say we wanted to convert this vector into a `MLIRSparseTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f85154f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 12,  0,  0, 34,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vector = np.array([0, 0, 12, 0, 0, 34, 0, 0], dtype=np.int32)\n",
    "dense_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c7708",
   "metadata": {},
   "source": [
    "We would normally have to explicitly pass in the indices, values, shape, etc. into the constructor for `MLIRSparseTensor` as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc8079ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array([2, 5], dtype=np.uint64)\n",
    "values = np.array([12, 34], dtype=np.int32)\n",
    "sizes = np.array([8], dtype=np.uint64)\n",
    "sparsity = np.array([True], dtype=np.bool8)\n",
    "explicitly_generated_sparse_vector = MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c251c3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlir_graphblas.sparse_utils.MLIRSparseTensor at 0x7fa0c05fff40>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicitly_generated_sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91a1854c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicitly_generated_sparse_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fd81363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2], dtype=uint64),)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicitly_generated_sparse_vector.pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "148ab3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 5], dtype=uint64),)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicitly_generated_sparse_vector.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92b80814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 34], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicitly_generated_sparse_vector.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52191d15",
   "metadata": {},
   "source": [
    "We can avoid writing such verbose code using `sparsify_array`. We only need to pass in the desired sparsity for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62edbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vector = sparsify_array(dense_vector, [True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e7b0ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlir_graphblas.sparse_utils.MLIRSparseTensor at 0x7fa0c0606a90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee35b529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59ad3608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2], dtype=uint64),)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector.pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "346924d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 5], dtype=uint64),)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fff02db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 34], dtype=int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e61512",
   "metadata": {},
   "source": [
    "We'll show examples of how to use `sparsify_array` with matrices below. Note that `sparsify_array` works with any ranked tensor (not just vectors and matrices) as long as the appropriate sparsity values are provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c737d98f",
   "metadata": {},
   "source": [
    "## Overview of `densify_*` Utilities\n",
    "\n",
    "Very often when debugging or testing, it is useful to be able to convert a `MLIRSparseTensor` into a dense tensor represented as an array in [NumPy](https://numpy.org/). \n",
    "\n",
    "`densify_vector`, `densify_csr`, and `densify_csc` from `mlir_graphblas.tools.utils` allow us to do this. These functions will treat missing values as zeros. It's worth noting that this isn't necessarily the correct behavior for all applications, so it's always worth sanity checking what the assumed value is for the missing values.\n",
    "\n",
    "Let's first convert the sparse vectors we created above into dense numpy vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd4ca21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 12,  0,  0, 34,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densify_vector(explicitly_generated_sparse_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a18af53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 12,  0,  0, 34,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densify_vector(sparse_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1449e13",
   "metadata": {},
   "source": [
    "We can also convert [CSR](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)) and CSC matrices into [NumPy](https://numpy.org/) matrices.\n",
    "\n",
    "Let's first create a [CSR](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)) matrix via `sparsify_array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae575747",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_matrix = np.array(\n",
    "    [\n",
    "        [1, 0, 0, 0, 0],\n",
    "        [0, 2, 3, 0, 0],\n",
    "        [0, 0, 4, 0, 0],\n",
    "        [0, 0, 5, 6, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "    ],\n",
    "    dtype=np.float64,\n",
    ")\n",
    "csr_matrix = sparsify_array(dense_matrix, [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81d52f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlir_graphblas.sparse_utils.MLIRSparseTensor at 0x7fa0c0614360>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "501fcf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ccc745a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=uint64), array([0, 1, 3, 4, 6, 6], dtype=uint64))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix.pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5124de27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=uint64), array([0, 1, 2, 2, 2, 3], dtype=uint64))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "976c169b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff68a9d",
   "metadata": {},
   "source": [
    "Let's now create a dense matrix from this [CSR](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa7b6c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 2., 3., 0., 0.],\n",
       "       [0., 0., 4., 0., 0.],\n",
       "       [0., 0., 5., 6., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_trip_dense_matrix = densify_csr(csr_matrix)\n",
    "round_trip_dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0bdc9796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_trip_dense_matrix.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2418c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(dense_matrix == round_trip_dense_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235a723",
   "metadata": {},
   "source": [
    "As mentioned in the [ops reference](../../ops_reference.ipynb), the only difference between CSR and CSC is the indexing. Since MLIR's sparse tensor data structures do not store the indexing, `MLIRSparseTensor` also does not. `MLIRSparseTensor`'s constructor assumes that the indexing simply uses row oriented indexing. Thus, it's not possible to know whether a matrix with `[False, True]` sparsity uses a CSR or CSC layout. Thus, when converting a CSR or CSC `MLIRSparseTensor` instance into a dense [NumPy](https://numpy.org/) matrix, we must explicitly use `densify_csr` or `densify_csc`.\n",
    "\n",
    "Since we can't explicitly create a CSC matrix via `MLIRSparseTensor`'s constructor alone, we'll delay showing demonstrations of how to use `densify_csc` until later tutorials using ops from the GraphBLAS dialect that manipulate a sparse tensor's layout, e.g. `graphblas.convert_layout`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
